<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Apache Doris Blog</title>
        <link>https://doris.apache.org/zh-CN/blog</link>
        <description>Apache Doris Blog</description>
        <lastBuildDate>Mon, 15 Aug 2022 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>zh-CN</language>
        <item>
            <title><![CDATA[Apache Doris 在小米数据场景的应用实践与优化]]></title>
            <link>https://doris.apache.org/zh-CN/blog/xiaomi</link>
            <guid>/xiaomi</guid>
            <pubDate>Mon, 15 Aug 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[<!--]]></description>
            <content:encoded><![CDATA[<h1>背景</h1><p>因增长分析业务需要，小米集团于 2019 年首次引入了 Apache Doris 。经过三年时间的发展，目前 Apache Doris 已经在广告投放、新零售、增长分析、数据看板、天星数科、小米有品、用户画像等小米内部数十个业务中得到广泛应用 <strong>，并且在小米内部已经形成一套以 Apache Doris 为核心的数据生态。</strong>
<img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/25d7c2c45acd4e1c8c1a1742016fc6b9~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q">
当前 Apache Doris 在小米内部已经具有<strong>数十个</strong>集群、总体达到<strong>数百台</strong> BE 节点的规模，其中单集群最大规模达到<strong>近百台节点</strong>，拥有<strong>数十个</strong>流式数据导入产品线，每日单表最大增量 <strong>120 亿</strong>、支持 <strong>PB 级别</strong>存储，单集群每天可以支持 <strong>2W 次以上</strong>的多维分析查询。</p><h1>架构演进</h1><p>小米引入 Apache Doris 的初衷是为了解决内部进行用户行为分析时所遇到的问题。随着小米互联网业务的发展，各个产品线利用用户行为数据对业务进行增长分析的需求越来越迫切。让每个业务产品线都自己搭建一套增长分析系统，不仅成本高昂，也会导致效率低下。因此能有一款产品能够帮助他们屏蔽底层复杂的技术细节，让相关业务人员能够专注于自己的技术领域，可以极大提高工作效率。基于此，小米大数据和云平台联合开发了增长分析系统 Growing Analytics（下文中简称 GA )，旨在提供一个灵活的多维实时查询和分析平台，统一数据接入和查询方案，帮助业务线做精细化运营。（此处内容引用自：<a href="https://mp.weixin.qq.com/s?__biz=MzUxMDQxMDMyNg==&amp;mid=2247486817&amp;idx=1&amp;sn=99fbef15b4d6f6059c3affbc77517e6e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener noreferrer">基于Apache Doris的小米增长分析平台实践</a>）</p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/897a0453e1a540ae88cdf05ee9188b56~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p>分析、决策、执行是一个循环迭代的过程，在对用户进行行为分析后，针对营销策略是否还有提升空间、是否需要在前端对用户进行个性化推送等问题进行决策，帮助小米实现业务的持续增长。这个过程是对用户行为进行<strong>分析-决策-优化执行-再分析-再决策-再优化执行</strong>的迭代过程。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="历史架构">历史架构<a class="hash-link" href="#历史架构" title="标题的直接链接">​</a></h3><p>增长分析平台立项于 2018 年年中，当时基于开发时间和成本，技术栈等因素的考虑，小米复用了现有各种大数据基础组件（HDFS, Kudu, SparkSQL 等），搭建了一套基于 Lamda 架构的增长分析查询系统。<strong>GA 系统初代版本的架构如下图所示，包含了以下几个方面：</strong></p><ul><li>数据源：数据源是前端的埋点数据以及可能获取到的用户行为数据。</li><li>数据接入层：对埋点数据进行统一的清洗后打到小米内部自研的消息队列 Talos 中，并通过 Spark Streaming 将数据导入存储层 Kudu 中。</li><li>存储层：在存储层中进行冷热数据分离。热数据存放在 Kudu 中，冷数据则会存放在 HDFS 上。同时在存储层中进行分区，当分区单位为天时，每晚会将一部分数据转冷并存储到 HDFS 上。</li><li>计算层/查询层：在查询层中，使用 SparkSQL 对 Kudu 与 HDFS 上数据进行联合视图查询，最终把查询结果在前端页面上进行显示。</li></ul><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9039c4f9ef8a4a3cbfd092b21233e831~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p><strong>在当时的历史背景下，初代版本的增长分析平台帮助我们解决了一系列用户运营过程中的问题，但同时在历史架构中也存在了两个问题：</strong></p><p><strong>第一个问题：</strong> 由于历史架构是基于 SparkSQL + Kudu + HDFS 的组合，依赖的组件过多导致运维成本较高。原本的设计是各个组件都使用公共集群的资源，但是实践过程中发现执行查询作业的过程中，查询性能容易受到公共集群其他作业的影响，容易抖动，尤其在读取 HDFS 公共集群的数据时，有时较为缓慢。</p><p><strong>第二个问题：</strong> 通过 SparkSQL 进行查询时，延迟相对较高。SparkSQL 是基于批处理系统设计的查询引擎，在每个 Stage 之间交换数据 Shuffle 的过程中依然需要落盘操作，完成 SQL 查询的时延较高。为了保证 SQL 查询不受资源的影响，我们通过添加机器来保证查询性能，但是实践过程中发现，性能提升的空间有限，这套解决方案并不能充分地利用机器资源来达到高效查询的目的，存在一定的资源浪费。 <strong>（此处内容引用自：<a href="https://mp.weixin.qq.com/s?__biz=MzUxMDQxMDMyNg==&amp;mid=2247486817&amp;idx=1&amp;sn=99fbef15b4d6f6059c3affbc77517e6e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener noreferrer">基于Apache Doris的小米增长分析平台实践</a>）</strong></p><p>针对上述两个问题，我们的目标是寻求一款计算存储一体的 MPP 数据库来替代我们目前的存储计算层的组件，<strong>在通过技术选型后，最终我们决定使用 Apache Doris 替换老一代历史架构。</strong></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="基于-apache-doris-的新版架构">基于 Apache Doris 的新版架构<a class="hash-link" href="#基于-apache-doris-的新版架构" title="标题的直接链接">​</a></h3><p>当前架构从数据源获取前端埋点数据后，通过数据接入层打入 Apache Doris 后可以直接查询结果并在前端进行显示。<img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/540f5fa779af4b629869e54b793ea273~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p><strong>选择 Doris 原因：</strong></p><ul><li><p>Doris 具有优秀的查询性能，能够满足业务需求。</p></li><li><p>Doris 支持标准 SQL ，用户使用与学习成本较低。</p></li><li><p>Doris 不依赖于其他的外部系统，运维简单。</p></li><li><p>Doris 社区拥有很高活跃度，有利于后续系统的维护升级。</p></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="新旧架构性能对比">新旧架构性能对比<a class="hash-link" href="#新旧架构性能对比" title="标题的直接链接">​</a></h3><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ada8246b409a4cb6b11ffd2454aa2b06~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p>我们选取了日均数据量大约 10 亿的业务，分别在不同场景下进行了性能测试，其中包含 6 个事件分析场景，3 个留存分析场景以及 3 个漏斗分析场景。<strong>经过对比后，得出以下结论：</strong></p><ul><li>在事件分析的场景下，平均查询所耗时间<strong>降低了 85%</strong> 。</li><li>在留存分析和漏斗分析场景下，平均查询所耗时间<strong>降低了 50%</strong> <strong>。</strong></li></ul><h1>应用实践</h1><p>随着接入业务的增多和数据规模的增长，让我们也遇到不少问题和挑战，下面我们将介绍在<strong>使用 Apache Doris 过程中沉淀出来的一些实践经验</strong>。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="数据导入">数据导入<a class="hash-link" href="#数据导入" title="标题的直接链接">​</a></h3><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8afce198933f4ca4b2c97d4cf85b27de~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q">小米内部主要通过 Stream Load 与 Broker Load 以及少量 Insert 方式来进行 Doris 的数据导入。数据一般会先打到 Talos 消息队列中，并分为实时数据和离线数据两个部分。</p><p><strong>实时数据写入 Apache Doris 中：</strong></p><p> 一部分业务在通过 Flink 对数据进行处理后，会通过 Doris 社区提供的 Flink Doris Connector 组件写入到 Doris 中，底层依赖于 Doris Stream Load 数据导入方式。也有一部分会通过 Spark Streaming 封装的 Stream Load 将数据导入到 Doris 中。</p><p><strong>离线数据写入</strong> <strong>Apache Doris 中：</strong></p><p>离线数据部分则会先写到 Hive 中，再通过小米的数据工场将数据导入到 Doris 中。用户可以直接在数据工场提交 Broker Load 任务并将数据直接导入 Doris 中，也可以通过 Spark SQL 将数据导入 Doris 中。Spark SQL 方式则是依赖了 Doris 社区提供的 Spark Doris Connector 组件，底层也是对 Doris 的 Stream Load 数据导入方式进行的封装。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="数据查询">数据查询<a class="hash-link" href="#数据查询" title="标题的直接链接">​</a></h3><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8c1cd3554e854dbe99aba27499e28118~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p>用户通过数据工场将数据导入至 Doris 后即可进行查询，在小米内部是通过小米自研的数鲸平台来做查询的。用户可以通过数鲸平台对 Doris 进行查询可视化，并实现用户行为分析（为满足业务的事件分析、留存分析、漏斗分析、路径分析等行为分析需求，我们为 Doris 添加了相应的 UDF 和 UDAF ）和用户画像分析。</p><p>虽然目前依然需要将 Hive 的数据导过来，但 Doris 社区也正在支持湖仓一体能力，在后续实现湖仓一体能力后，我们会考虑直接通过 Doris 查询 Hive 与 Iceberg 外表。<strong>值得一提的是，Doris 1.1 版本已经实现支持查询 Iceberg 外表能力。</strong> 同时在即将发布的 <strong>1.2 版本</strong>中，还将支持 Hudi 外表并增加了 Multi Catalog ，可以实现外部表元数据的同步，无论是查询外部表的性能还是接入外表的易用性都有了很大的提升。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="compaction-调优">Compaction 调优<a class="hash-link" href="#compaction-调优" title="标题的直接链接">​</a></h3><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/92ad4ea90c564af2b720080b449c6edf~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p>Doris 底层采用类似 LSM-Tree 方式，支持快速的数据写入。每一次的数据导入都会在底层的 Tablet 下生成一个新的数据版本，每个数据版本内都是一个个小的数据文件。单个文件内部是有序的，但是不同的文件之间又是无序的。为了使数据有序，在 Doris 底层就会存在 Compaction 机制，异步将底层小的数据版本合并成大的文件。Compaction 不及时就会造成版本累积，增加元数据的压力，并影响查询性能。由于 Compaction 任务本身又比较耗费机器CPU、内存与磁盘资源，如果 Compaction 开得太大就会占用过多的机器资源并影响到查询性能，同时也可能会造成 OOM。<strong>针对以上问题，我们一方面从业务侧着手，通过以下方面引导用户：</strong></p><ul><li>通过引导业务侧进行合理优化，对表设置<strong>合理的分区和分桶</strong>，避免生成过多的数据分片。</li><li>引导用户尽量<strong>降低数据的导入频率</strong> <strong>，</strong> <strong>增大单次数据导入的量</strong>，降低 Compaction 压力。</li><li>引导用户<strong>避免过多使用会在底层生成 Delete 版本的 Delete 操作</strong>。在 Doris 中 Compaction 分为 Base Compaction 与 Cumulative Compaction。Cumulative Compaction 会快速的把大量新导入的小版本进行快速的合并，在执行过程中若遇到 Delete 操作就会终止并将当前 Delete 操作版本之前的所有版本进行合并。由于 Cumulative Compaction 无法处理 Delete 版本，在合并完之后的版本会和当前版本一起放到 Base Compaction 中进行。当 Delete 版本特别多时， Cumulative Compaction 的步长也会相应变短，只能合并少量的文件，导致 Cumulative Compaction 不能很好的发挥小文件合并效果。</li></ul><p><strong>另一方面我们从运维侧着手：</strong></p><ul><li><strong>针对不同的业务集群配置不同的 Compaction 参数。</strong> 部分业务是实时写入数据的，需要的查询次数很多，我们就会将 Compaction 开的大一点以达到快速合并目的。而另外一部分业务只写今天的分区，但是只对之前的分区进行查询，在这种情况下，我们会适当的将 Compaction 放的小一点，避免 Compaction 占用过大内存或 CPU 资源。到晚上导入量变少时，之前导入的小版本能够被及时合并，对第二天查询效率不会有很大影响。</li><li><strong>适当降低 Base Compaction 任务优先级并增加 Cumulative Compaction 优先级。</strong> 根据上文提到的内容，Cumulative Compaction 能够快速合并大量生成的小文件，而 Base Compaction 由于合并的文件较大，执行的时间也会相应变长，读写放大也会比较严重。所以我们希望 Cumulative Compaction 优先、快速的进行。</li><li><strong>增加版本积压报警。</strong> 当我们收到版本积压报警时，动态调大 Compaction 参数，尽快消耗积压版本。</li><li><strong>支持手动触发指定表与分区下数据分片的 Compaction 任务。</strong> 由于 Compaction 不及时，部分表在查询时版本累积较多并需要能够快速进行合并。所以，我们支持对单个表或单个表下的某个分区提高 Compaction 优先级。</li></ul><p><strong>目前 Doris 社区针对以上问题已经做了</strong> <strong>一系列的优化</strong> <strong>，在 1.1 版本中</strong> <strong>大幅增强了数据 Compaction 能力，对于新增数据能够快速完成聚合，避免分片数据中的版本过多导致的 -235 错误以及带来的查询效率问题。</strong>\
<strong>首先</strong>，在 Doris 1.1 版本中，引入了 QuickCompaction，增加了主动触发式的 Compaction 检查，在数据版本增加的时候主动触发 Compaction。同时通过提升分片元信息扫描的能力，快速的发现数据版本多的分片，触发 Compaction。通过主动式触发加被动式扫描的方式，彻底解决数据合并的实时性问题。</p><p><strong>同时</strong>，针对高频的小文件 Cumulative Compaction，实现了 Compaction 任务的调度隔离，防止重量级的 Base Compaction 对新增数据的合并造成影响。</p><p><strong>最后</strong>，针对小文件合并，优化了小文件合并的策略，采用梯度合并的方式，每次参与合并的文件都属于同一个数据量级，防止大小差别很大的版本进行合并，逐渐有层次的合并，减少单个文件参与合并的次数，能够大幅的节省系统的 CPU 消耗。<img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cd2f0a547d6e4ddcb027715c4a544c5a~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"><strong>在社区 1.1 新版本的测试结果中，不论是Compaction 的效率、CPU 的资源消耗，还是高频导入时的查询抖动，效果都有了大幅的提升。</strong></p><p><strong>具体可以参考：</strong> <a href="http://mp.weixin.qq.com/s?__biz=Mzg3Njc2NDAwOA==&amp;mid=2247500848&amp;idx=1&amp;sn=a667665ed4ccf4cf807a47be7c264f69&amp;chksm=cf2fca37f85843219e2f74d856478d4aa24d381c1d6e7f9f6a64b65f3344ce8451ad91c5af97&amp;scene=21#wechat_redirect" target="_blank" rel="noopener noreferrer">Apache Doris 1.1 特性揭秘：Flink 实时写入如何兼顾高吞吐和低延时</a></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="监控报警">监控报警<a class="hash-link" href="#监控报警" title="标题的直接链接">​</a></h3><p>Doris 的监控主要是通过 Prometheus 以及 Grafana 进行。对于 Doris 的报警则是通过 Falcon 进行。</p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3fbe6b44f1124a91bf5ee17608f302d5~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q">小米内部使用 Minos 进行集群部署。Minos 是小米内部自研并开源的大数据服务进程管理工具。在完成 Doris 集群部署后会更新至小米内部的轻舟数仓中。在轻舟数仓中的节点注册到 ZooKeeper 后，Prometheus 会监听 ZooKeeper 注册的节点，同时访问对应端口，拉取对应 Metrics 。在这之后，Grafana 会在面板上对监控信息进行显示，若有指标超过预设的报警阈值，Falcon 报警系统就会在报警群内报警，同时针对报警级别较高或某些无法及时响应的警告，可直接通过电话呼叫值班同学进行报警。</p><p>另外，小米内部针对每一个 Doris 集群都有 Cloud - Doris 的守护进程。Could - Doris 最大功能是可以对 Doris 进行可用性探测。比如我们每一分钟对 Doris 发送一次 select current timestamp(); 查询，若本次查询 20 秒没有返回，我们就会判断本次探测不可用。小米内部对每一个集群的可用性进行保证，通过上述探测方法，可以在小米内部输出 Doris可用性指标。</p><h1>小米对Apache Doris的优化实践</h1><p>在应用 Apache Doris 解决业务问题的同时，我们也发现了 Apache Doris 存在的一些优化项，因此在与社区进行沟通后我们开始深度参与社区开发，解决自身问题的同时也及时将开发的重要 Feature 回馈给社区，具体包括 Stream Load 两阶段提交（2PC）、单副本数据导入、Compaction 内存限制等。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="stream-load-两阶段提交2pc">Stream Load 两阶段提交（2PC)<a class="hash-link" href="#stream-load-两阶段提交2pc" title="标题的直接链接">​</a></h3><p><strong>遇到的问题</strong></p><p>在 Flink 和 Spark 导入数据进 Doris 的过程中，当某些异常状况发生时可能会导致如下问题：</p><p><strong>Flink 数据重复导入</strong> <strong>：</strong> Flink 通过周期性 Checkpoint 机制处理容错并实现 EOS，通过主键或者两阶段提交实现包含外部存储的端到端 EOS。Doris-Flink-Connector 1.1 之前 UNIQUE KEY 表通过唯一键实现了EOS，非 UNIQUE KEY 表不支持 EOS。</p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e7750384cac44a569c8edf6c5de61744~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p> <strong>Spark SQL 数据部分导入</strong> <strong>：</strong> 通过 SparkSQL 从 Hive 表中查出的数据并写入 Doris 表中的过程需要使用到 Spark Doris Connector 组件，会将 Hive 中查询的数据通过多个 Stream Load 任务写入 Doris 中，出现异常时会导致部分数据导入成功，部分导入失败。</p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/936ffd500f364f838a9976584727ed42~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p><strong>Stream Load 两阶段提交设计</strong></p><p>以上两个问题可以通过导入支持两阶段提交解决，第一阶段完成后确保数据不丢且数据不可见，这就能保证第二阶段发起提交时一定能成功，也能够保证第二阶段发起取消时一定能成功。</p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/50e59f3a78f74ba6a8dd2d7960497adb~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p><strong>Doris 中的写入事务分为三步：</strong></p><ol><li>在  FE 上开始事务，状态为 Prepare ；</li><li>数据写入 BE；</li><li>多数副本写入成功的情况下，提交事务，状态变成 Committed，并且 FE 向 BE 下发 Publish Version 任务，让数据立即可见。</li></ol><p>引入两阶段提交之后，第 3 步变为状态修改为 Pre Commit，Publish Version 在第二阶段完成。用户在第一阶段完成后（事务状态为 Pre Commit ），可以选择在第二阶段放弃或者提交事务。</p><p><strong>支持 Flink Exactly-Once 语义</strong></p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ef5e0a81b441487ba7c3b3fa22e8c85d~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q">Doris-Flink-Connector 1.1 使用两阶段 Stream Load 并支持 Flink 两阶段提交实现了 EOS，只有全局的 Checkpoint 完成时，才会发起 Sream Load 的第二阶段提交，否则发起第二阶段放弃。</p><p><strong>解决 SparkSQL 数据部分导入</strong></p><p>Doris-Spark-Connector 使用两阶段 Stream Load 之后，成功的 Task 通过 Stream Load 第一阶段将写入数据到 Doris （Pre Commit 状态，不可见），当作业成功后，发起所有 Stream Load 第二阶段提交，作业失败时，发起所有 Stream Load 第二阶段取消。这就确保了不会有数据部分导入的问题。<img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/26b11a29566946c99b53ef90e01665ef~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="单副本数据导入优化">单副本数据导入优化<a class="hash-link" href="#单副本数据导入优化" title="标题的直接链接">​</a></h3><p><strong>单副本数据导入设计</strong></p><p><strong>Doris 通过多副本机制确保数据的高可靠以及系统高可用。</strong> 写入任务可以按照使用的资源分为计算和存储两类：排序、聚合、编码、压缩等使用的是 CPU 和内存的计算资源，最后的文件存储使用存储资源，三副本写入时计算和存储资源会占用三份。</p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a0012b34b7404e5482700c281f6c206f~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p>那能否只写一份副本数据在内存中，待到单副本写入完成并生成存储文件后，将文件同步到另外两份副本呢？答案是可行的，因此针对三副本写入的场景，我们做了单副本写入设计。<strong>单副本数据在内存中做完排序、聚合、编码以及压缩后，将文件同步至其他两个副本，这样很大程度上可以节省出 CPU 和内存资源。</strong></p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e3528e0d75184068aa3b50384cb548d1~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p><strong>性能对比测试</strong></p><p><strong>Broker Load 导入 62G 数据性能对比</strong>
<strong>导入时间：</strong> 三副本导入耗时 33 分钟，单副本导入耗时 31 分钟。</p><p><strong>内存使用：</strong> 内存使用上优化效果十分明显，三副本数据导入的内存使用是单副本导入的三倍。单副本导入时只需要写一份内存，但是三副本导入时需要写三份内存，内存优化达到了 3 倍。</p><p><strong>CPU 消耗对比：</strong> 三副本导入的 CPU 消耗差不多是单副本的三倍。</p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cbe6bb648e8d47d09c556eed4ffcdfa9~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p><strong>并发场景性能对比</strong></p><p>测试中向  100 个表并发导入数据，每个表有 50 个导入任务，任务总数为 5000 个。单个 Stream Load 任务导入的数据行是 200 万行，约为 90M 的数据。测试中开了 128 个并发，<strong>将</strong> <strong>单副本导入和三副本导入进行了对比：</strong></p><p><strong>导入时间：</strong> 3 副本导入耗时 67 分钟，而后单副本耗时 27 分钟完成。导入效率相当提升两倍以上。</p><p><strong>内存使用：</strong> 单副本的导入会更低。</p><p><strong>CPU消耗对比：</strong> 由于都已经是开了并发在导入，CPU开销都比较高，但是单副本导入吞吐提升明显。</p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5a4f5533c4184f8caab39c38d951e410~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p><strong>Compaction 内存限制</strong></p><p>之前 Doris 在单机磁盘一次导入超过 2000 个 Segment 的情况下，Compaction 有内存 OOM 的问题。对于当天写入但不查当天数据而是查询之前的数据业务场景，我们会把 Compaction 稍微放的小一点，避免占用太大的内存，导致进程 OOM。Doris 之前每个磁盘有固定的线程做存储在这个盘上的数据的 Compaction，没有办法在全局进行管控。因为我们要限制单个节点上面内存的使用，<strong>所以我们将该模式改成了生产者-消费者模式：</strong></p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ede14473f9104bdc89213e82398ba32a~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p>生产者不停的从所有的磁盘上面生产任务，之后将生产任务提交到线程池中。我们可以很好的把控线程池的入口，达到对 Compaction 的限制。我们在合并时会把底层的小文件进行归并排序，之后在内存里给每一个文件开辟 Block，所以我们可以近似认为占用的内存量与文件的数量是相关的，从而可以通过对单节点上同时执行合并的文件数量做限制，来达到控制内存的效果。</p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/00803f23d5a0427fb57abde4a2b1ec2d~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p><strong>我们增加了对单个 BE Compaction 合并的文件数量的限制。</strong> 若正在进行的 Compaction 的文件数量超过或等于当前限制时，后续提交上来的任务就需要等待，等到前面的 Compaction 任务做完并将指标释放出来后，后边提交进来的那些任务才可以进行。</p><p>通过这种方式，我们对某些业务场景做了内存的限制，很好的避免集群负载高时占用过多内存导致 OOM 的问题。</p><h1>总结</h1><p>自从 Apache Doris 从 2019 年上线第一个业务至今，<strong>目前 Apache Doris 已经在小米内部服务了数十个业务、集群数量达到数十个、节点规模达到数百台、每天完成数万次用户在线分析查询，承担了包括增长分析和报表查询等场景绝大多数在线分析的需求。</strong></p><p>与此同时，以上所列小米对于 Apache Doris 的优化实践，已经有部分功能已经在 Apache Doris 1.0 或 1.1 版本中发布，有部分 PR 已经合入社区 Master，在不久后发布的 1.2 新版本中应该就会与大家见面。随着社区的快速发展，有越来越多小伙伴参与到社区建设中，社区活跃度有了极大的提升。Apache Doris 已经变得越来越成熟，并开始从单一计算存储一体的分析型 MPP 数据库走向湖仓一体的道路，相信在未来还有更多的数据分析场景等待去探索和实现。</p>]]></content:encoded>
            <category>最佳实践</category>
        </item>
        <item>
            <title><![CDATA[Apache Doris 1.1 特性揭秘：Flink 实时写入如何兼顾高吞吐和低延时]]></title>
            <link>https://doris.apache.org/zh-CN/blog/Flink-realtime-write</link>
            <guid>/Flink-realtime-write</guid>
            <pubDate>Fri, 29 Jul 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[<!--]]></description>
            <content:encoded><![CDATA[<h1>背景</h1><p>随着数据实时化需求的日益增多，数据的时效性对企业的精细化运营越来越重要，在海量数据中，如何能实时有效的挖掘出有价值的信息，快速的获取数据反馈，协助公司更快的做出决策，更好的进行产品迭代，<strong>实时数仓在这一过程中起到了不可替代的作用</strong>。</p><p>在这种形势下，<strong>Apache Doris 作为一款实时 MPP 分析型数据库脱颖而出</strong>，同时具备高性能、简单易用等特性，具有丰富的数据接入方式，结合 Flink 流式计算，可以让用户快速将 Kafka 中的非结构化数据以及 MySQL 等上游业务库中的变更数据，快速同步到 Doris 实时数仓中，同时 Doris 提供亚秒级分析查询的能力，可以有效地满足实时 OLAP、实时数据看板以及实时数据服务等场景的需求。</p><h1>挑战</h1><p>通常实时数仓要保证端到端高并发以及低延迟，往往面临诸多挑战，比如：</p><ul><li>如何保证端到端的<strong>秒级别数据同步</strong>？</li><li>如何快速保证<strong>数据可见性</strong>？</li><li>在高并发大压力下，如何解决<strong>大量小文件写入</strong>的问题？</li><li>如何确保端到端的 <strong>Exactly Once</strong> 语义？</li></ul><p>结合这些挑战，同时对用户使用 Flink+Doris 构建实时数仓的业务场景进行深入调研，在掌握了用户使用的痛点之后，<strong>我们在 Doris 1.1 版本中进行了针对性的优化，大幅提升实时数仓构建的用户体验，同时提升系统的稳定性，系统资源消耗也得到了大幅的优化。</strong></p><h1>优化</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="流式写入">流式写入<a class="hash-link" href="#流式写入" title="标题的直接链接">​</a></h2><p>Flink Doris Connector 最初的做法是在接收到数据后，缓存到内存 Batch 中，通过攒批的方式进行写入，同时使用 batch.size、batch.interval 等参数来控制 Stream Load 写入的时机。这种方式通常在参数合理的情况下可以稳定运行，一旦参数不合理导致频繁的 Stream Load，便会引发 Compaction 不及时，从而导致 version 过多的错误(-235)；其次，当数据过多时，为了减少 Stream Load 的写入时机，batch.size 过大的设置还可能会引发 Flink 任务的 OOM。为了解决这个问题，<strong>我们引入了流式写入</strong> <strong>：</strong> <img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7b4b7364deb34a1398c496d10890a249~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><ol><li><p>Flink 任务启动后，会异步发起一个 Stream Load 的 Http 请求。</p></li><li><p>接收到实时数据后，通过 Http 的分块传输编码(Chunked transfer encoding)机制持续向 Doris 传输数据。</p></li><li><p>在 Checkpoint 时结束 Http 请求，完成本次 Stream Load 写入，同时异步发起下一次 Stream Load 的请求。</p></li><li><p>继续接收实时数据，后续流程同上。</p></li></ol><p><strong>由于采用 Chunked 机制传输数据，就避免了攒批对内存的压力，同时将写入的时机和 Checkpoint 绑定起来，使得 Stream Load 的时机可控，并且为下面的 Exactly-Once 语义提供了基础。</strong></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="exactly-once">Exactly-Once<a class="hash-link" href="#exactly-once" title="标题的直接链接">​</a></h2><p>Exactly-Once 语义是指即使在机器或应用出现故障的情况下，也不会重复处理数据或者丢失数据。Flink 很早就支持 End-to-End 的 Exactly-Once 场景，主要是通过两阶段提交协议来实现 Sink 算子的 Exactly-Once 语义。在 Flink 两阶段提交的基础上，同时借助 Doris 1.0 的 Stream Load 两阶段提交，<strong>Flink Doris Connector 实现了 Exactly Once 语义，具体原理如下：</strong></p><ol><li>Flink 任务在启动的时候，会发起一个 Stream Load 的 PreCommit 请求，此时会先开启一个事务，同时会通过 Http 的 Chunked 机制将数据持续发送到 Doris。</li></ol><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9b2f143faf784500a3a8ba34063d6c2e~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><ol start="2"><li>在 Checkpoint 时，结束数据写入，同时完成 Http 请求，并且将事务状态设置为预提交(PreCommitted)，此时数据已经写入 BE，对用户不可见。</li></ol><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e7e1d4f76a824c9a8f473e2e266defc4~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><ol start="3"><li>Checkpoint 完成后，发起 Commit 请求，并且将事务状态设置为提交(Committed)，完成后数据对用户可见。</li></ol><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1215aaa4dc3e44de86cdd4680ac30b00~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><ol start="4"><li>Flink 应用意外挂掉后，从 Checkpoint 重启时，若上次事务为预提交(PreCommitted)状态，则会发起回滚请求，并且将事务状态设置为 Aborted。</li></ol><p><strong>基于此，可以借助 Flink Doris Connector 实现数据实时入库时数据不丢不重。</strong></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="秒级别数据同步">秒级别数据同步<a class="hash-link" href="#秒级别数据同步" title="标题的直接链接">​</a></h2><p>高并发写入场景下的端到端秒级别数据同步以及数据的实时可见能力，<strong>需要 Doris 具备如下几方面的能力：</strong></p><p><strong>事务处理能力</strong></p><p>Flink 实时写入以 Stream Load 2PC 的方式与 Doris 进行交互，需要 Doris 具备对应的事务处理能力，保障事务基本的 ACID 特性，在高并发场景下支撑 Flink 秒级别的数据同步。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="数据版本的快速聚合能力">数据版本的快速聚合能力<a class="hash-link" href="#数据版本的快速聚合能力" title="标题的直接链接">​</a></h2><p>Doris 里面一次导入会产生一个数据版本，在高并发写入场景下必然带来的一个影响是数据版本过多，且单次导入的数据量不会太大。持续的高并发小文件写入场景对 Doris 并不友好，极其考验 Doris 数据合并的实时性以及性能，进而会影响到查询的性能。<strong>Doris 在 1.1 中大幅增强了数据 Compaction 能力，对于新增数据能够快速完成聚合，避免分片数据中的版本过多导致的 -235 错误以及带来的查询效率问题。</strong> </p><p><strong>首先</strong>，在 Doris 1.1 版本中，引入了 QuickCompaction，增加了主动触发式的 Compaction 检查，在数据版本增加的时候主动触发 Compaction。同时通过提升分片元信息扫描的能力，快速的发现数据版本多的分片，触发 Compaction。通过主动式触发加被动式扫描的方式，彻底解决数据合并的实时性问题。</p><p><strong>同时</strong>，针对高频的小文件 Cumulative Compaction，实现了 Compaction 任务的调度隔离，防止重量级的 Base Compaction 对新增数据的合并造成影响。</p><p><strong>最后</strong>，针对小文件合并，优化了小文件合并的策略，采用梯度合并的方式，每次参与合并的文件都属于同一个数据量级，防止大小差别很大的版本进行合并，逐渐有层次的合并，减少单个文件参与合并的次数，能够大幅的节省系统的 CPU 消耗。<img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fee6ce47ed6d4c21a34ca35c3a3ad4df~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p><strong>Doris 1.1 对高并发导入、秒级别数据同步、数据实时可见等场景都做了针对性优化，大大增加了 Flink + Doris 系统的易用性以及稳定性，节省了集群整体资源。</strong></p><h1>效果</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="通用-flink-高并发场景">通用 Flink 高并发场景<a class="hash-link" href="#通用-flink-高并发场景" title="标题的直接链接">​</a></h2><p>在调研的通用场景中，使用 Flink 同步上游 Kafka 中的非结构化数据，经过 ETL 后使用 Flink Doris Connector 将数据实时写入 Doris 中。这里客户场景极其严苛，上游维持以每秒 10w 的超高频率写入，需要数据能够在 5s 内完成上下游同步，实现秒级别的数据可见。这里 Flink 配置为 20 并发，Checkpoint 间隔 5s，Doris 1.1 的表现相当优异。<strong>具体体现在如下几个方面：</strong></p><p><strong>Compaction 实时性</strong></p><p>数据能快速合并，Tablet 数据版本个数维持在 50 以下， Compaction Score 稳定。相比于之前高并发导入频出的 -235 问题，<strong>Compaction 合并效率有 10+ 倍提升</strong>。</p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f622b2f235ae4bad8b2b38fd9d1f0c57~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p><strong>CPU 资源消耗</strong></p><p>Doris 1.1 针对小文件的 Compaction 进行了策略优化，在上述高并发导入场景，<strong>CPU 资源消耗下降 25%。</strong> <img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ec2732a96bf047e283465b04452c063a~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p><strong>QPS 查询延迟稳定</strong></p><p>通过降低 CPU 使用率，减少数据版本的个数，提升了数据整体有序性，从而减少了 SQL 查询的延迟。<img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9f49f45e950045c0b7913dd167c8d220~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="秒级别数据同步场景极限大压力">秒级别数据同步场景（极限大压力）<a class="hash-link" href="#秒级别数据同步场景极限大压力" title="标题的直接链接">​</a></h2><p>单 BE 单 Tablet，客户端 30 并发极限 Stream Load 压测，数据在实时性&lt;1s，Compaction Score 优化前后对比</p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/209083a2f22846688f02454e306e0053~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><h1>使用建议</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="数据实时可见场景">数据实时可见场景<a class="hash-link" href="#数据实时可见场景" title="标题的直接链接">​</a></h2><p>对延迟要求特别严格的场景，比如秒级别数据同步，通常意味着单次导入文件较小，此时建议调小 cumulative_size_based_promotion_min_size_mbytes，单位是 MB，默认 64，可以设置成 8，能够很大程度提升 Compaction 的实时性。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="高并发场景">高并发场景<a class="hash-link" href="#高并发场景" title="标题的直接链接">​</a></h2><p>对于高并发的写入场景，可以通过增加 Checkpoint 的间隔来减少 Stream Load 的频率，比如 Checkpoint 可以设置为 5-10s，不仅可以增加 Flink 任务的吞吐，也可以减少小文件的产生，避免给 Compaction 造成更多压力。</p><p>此外，对数据实时性要求不高的场景，比如分钟级别的数据同步，可以增加 Checkpoint 的间隔，比如 5-10 分钟，此时 Flink Doris Connector 依然能够通过两阶段提交 +checkpoint 机制来保证数据的完整性。</p><h1>未来规划</h1><p><strong>实时 Schema Change</strong></p><p>目前通过 Flink CDC 实时接入数据时，当上游业务表进行 Schema Change 操作时，必须先手动修改 Doris 中的 Schema 和 Flink 任务中的 Schema，最后再重启任务，新的 Schema 的数据才可以同步过来。这样使用方式需要人为的介入，会给用户带来极大的运维负担。<strong>后续会针对 CDC 场景做到支持 Schema 实时变更，上游的 Schema Change 实时同步到下游，全面提升 Schema Change 的效率。</strong></p><p><strong>Doris 多表写入</strong></p><p>目前 Doris Sink 算子仅支持同步单张表，所以对于整库同步的操作，需要手动在 Flink 层面进行分流，写到多个 Doris Sink 中，这无疑增加了开发者的难度，<strong>在后续版本中我们也将支持单个 Doris Sink 同步多张表，这样就大大的简化了用户的操作。</strong></p><p><strong>自适应的 Compaction 参数调优</strong></p><p>目前 Compaction 策略参数较多，在大部分通用场景能发挥较好的效果，但是在一些特殊场景下并不能高效的发挥作用。<strong>我们将在后续版本中持续优化，针对不同的场景，进行自适应的 Compaction 调优，在各类场景下提高数据合并效率，提升实时性。</strong></p><p><strong>单副本 Compaction</strong></p><p>目前的 Compaction 策略是各 BE 单独进行，<strong>在后续版本中我们将实现单副本 Compaction，通过克隆快照的方式实现 Compaction 任务，减少集群 2/3 的 Compaction 任务，降低系统的负载，把更多的系统资源留给用户侧。</strong></p>]]></content:encoded>
            <category>技术解析</category>
        </item>
        <item>
            <title><![CDATA[[Doris 发版通告] Apache Doris 1.1.1 Release]]></title>
            <link>https://doris.apache.org/zh-CN/blog/release-1.1.1</link>
            <guid>/release-1.1.1</guid>
            <pubDate>Fri, 29 Jul 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[<!--]]></description>
            <content:encoded><![CDATA[<h2 class="anchor anchorWithStickyNavbar_LWe7" id="新增功能">新增功能<a class="hash-link" href="#新增功能" title="标题的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="向量化执行引擎支持-odbc-sink">向量化执行引擎支持 ODBC Sink。<a class="hash-link" href="#向量化执行引擎支持-odbc-sink" title="标题的直接链接">​</a></h3><p>在 1.1.0 版本的向量化执行引擎中 ODBC Sink 是不支持的，而这一功能在之前版本的行存引擎是支持的，因此在 1.1.1 版本中我们重新完善了这一功能。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="增加简易版-memtracker">增加简易版 MemTracker<a class="hash-link" href="#增加简易版-memtracker" title="标题的直接链接">​</a></h3><p>MemTracker 是一个用于分析内存使用情况的统计工具，在 1.1.0 版本的向量化执行引擎中，由于 BE 侧没有 MemTracker，可能出现因内存失控导致的 OOM 问题。在 1.1.1 版本中，BE 侧增加了一个简易版 MemTracker，可以帮助控制内存，并在内存超出时取消查询。</p><p>完整版 MemTracker 将在 1.1.2 版本中正式发布。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="改进">改进<a class="hash-link" href="#改进" title="标题的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持在-page-cache-中缓存解压后数据">支持在 Page Cache 中缓存解压后数据。<a class="hash-link" href="#支持在-page-cache-中缓存解压后数据" title="标题的直接链接">​</a></h3><p>在 Page Cache 中有些数据是用 bitshuffle 编码方式压缩的，在查询过程中需要花费大量的时间来解压。在 1.1.1 版本中，Doris 将缓存解压由 bitshuffle 编码的数据以加速查询，我们发现在 ssb-flat 的一些查询中，可以减少 30% 的延时。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="bug-修复">Bug 修复<a class="hash-link" href="#bug-修复" title="标题的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="修复无法从-10-版本进行滚动升级的问题">修复无法从 1.0 版本进行滚动升级的问题。<a class="hash-link" href="#修复无法从-10-版本进行滚动升级的问题" title="标题的直接链接">​</a></h3><p>这个问题是在 1.1.0 版本中出现的，当升级 BE 而不升级 FE 时，可能会导致 BE Core。</p><p>如果你遇到这个问题，你可以尝试用 <a href="https://github.com/apache/doris/pull/10833" target="_blank" rel="noopener noreferrer">#10833</a> 来修复它。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="修复某些查询不能回退到非向量化引擎的问题并导致-be-core">修复某些查询不能回退到非向量化引擎的问题，并导致 BE Core。<a class="hash-link" href="#修复某些查询不能回退到非向量化引擎的问题并导致-be-core" title="标题的直接链接">​</a></h3><p>目前，向量化执行引擎不能处理所有的 SQL 查询，一些查询（如 left outer join）将使用非向量化引擎来运行。但部分场景在 1.1.0 版本中未被覆盖到，这可能导致 BE 挂掉。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="修复-compaction-不能正常工作导致的--235-错误">修复 Compaction 不能正常工作导致的 -235 错误。<a class="hash-link" href="#修复-compaction-不能正常工作导致的--235-错误" title="标题的直接链接">​</a></h3><p>在 Unique Key 模型中，当一个 Rowset 有多个 Segment 时，在做 Compaction 过程中由于没有正确的统计行数，会导致Compaction 失败并且产生 Tablet 版本过多而导致的 -235 错误。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="修复查询过程中出现的部分-segment-fault">修复查询过程中出现的部分 Segment fault。<a class="hash-link" href="#修复查询过程中出现的部分-segment-fault" title="标题的直接链接">​</a></h3><p><a href="https://github.com/apache/doris/pull/10961" target="_blank" rel="noopener noreferrer">#10961</a>
<a href="https://github.com/apache/doris/pull/10954" target="_blank" rel="noopener noreferrer">#10954</a>
<a href="https://github.com/apache/doris/pull/10962" target="_blank" rel="noopener noreferrer">#10962</a></p><h1>致谢</h1><p>感谢所有参与贡献 1.1.1 版本的开发者:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@jacktengg</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@mrhhsg</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xinyiZzz</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@yixiutt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@starocean999</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@morrySnow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@morningman</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@HappenLee</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>]]></content:encoded>
            <category>版本发布</category>
        </item>
        <item>
            <title><![CDATA[Apache Doris 在京东客服 OLAP 中的应用实践]]></title>
            <link>https://doris.apache.org/zh-CN/blog/jd</link>
            <guid>/jd</guid>
            <pubDate>Wed, 20 Jul 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[<!--]]></description>
            <content:encoded><![CDATA[<h1><strong>引言</strong></h1><p>Apache Doris 是一款开源的 MPP 分析型数据库产品，不仅能够在亚秒级响应时间即可获得查询结果，有效的支持实时数据分析，而且支持 10PB 以上的超大的数据集。相较于其他业界比较火的 OLAP 数据库系统，Doris 的分布式架构非常简洁，支持弹性伸缩，易于运维，节省大量人力和时间成本。目前国内社区火热，也有美团、小米等大厂在使用。</p><p>本文主要讨论京东客服在人工咨询、客户事件单、售后服务单等专题的实时大屏，在实时和离线数据多维分析方面，如何利用 Doris 进行业务探索与实践。近些年来，随着数据量爆炸式的增长，以及海量数据联机分析需求的出现，MySQL、Oracle 等传统的关系型数据库在大数据量下遇到瓶颈，而 Hive、Kylin 等数据库缺乏时效性。于是 Apache Doris、Apache Druid、ClickHouse 等实时分析型数据库开始出现，不仅可以应对海量数据的秒级查询，更满足实时、准实时的分析需求。离线、实时计算引擎百花齐放。但是针对不同的场景，面临不同的问题，没有哪一种引擎是万能的。我们希望通过本文，对京东客服业务在离线与实时分析的应用与实践，能够给到大家一些启发，也希望大家多多交流，给我们提出宝贵的建议。</p><h1><strong>京东客服业务形态</strong></h1><p>京东客服作为集团服务的入口，为用户和商家提供了高效、可靠的保障。京东客服肩负着及时解决用户问题的重任，给用户提供详细易懂的说明与解释；为更好的了解用户的反馈以及产品的状况，需要实时的监控咨询量、接起率、投诉量等一系列指标，通过环比和同比，及时发现存在的问题，以更好的适应用户的购物方式，提高服务质量与效率，进而提高京东品牌的影响力。</p><h1><strong>Easy OLAP 设计</strong></h1><h3 class="anchor anchorWithStickyNavbar_LWe7" id="01-easyolap-doris-数据导入链路"><strong>01 EasyOLAP Doris 数据导入链路</strong><a class="hash-link" href="#01-easyolap-doris-数据导入链路" title="标题的直接链接">​</a></h3><p>EasyOLAP Doris 数据源主要是实时 Kafka 和离线 HDFS 文件。实时数据的导入依赖于 Routine Load 的方式；离线数据主要使用 Broker Load 和 Stream Load 的方式导入。</p><p><img loading="lazy" alt="EasyOLAP Doris 数据导入链路" src="/zh-CN/assets/images/jd03-00bd471f0fab2d98798f5e3148b35fce.png" width="1080" height="604" class="img_ev3q"></p><p>EasyOLAP Doris 数据导入链路</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="02-easyolap-doris-全链路监控"><strong>02 EasyOLAP Doris 全链路监控</strong><a class="hash-link" href="#02-easyolap-doris-全链路监控" title="标题的直接链接">​</a></h3><p>目前 EasyOLAP Doris 项目的监控，使用的是 Prometheus + Grafana 框架。其中 node_exporter 负责采集机器层面的指标，Doris 也会自动以 Prometheus 格式吐出 FE、BE 的服务层面的指标。另外，部署了 OLAP Exporter 服务用于采集 Routine Load 相关的指标，旨在第一时间发现实时数据流导入的情况，确保实时数据的时效性。</p><p><img loading="lazy" alt="EasyOLAP Doris monitoring link" src="/zh-CN/assets/images/jd04-8770adfb04ffe977f931d9eaff4cb534.png" width="1080" height="594" class="img_ev3q"></p><p>EasyOLAP Doris 监控链路</p><p><img loading="lazy" alt="640" src="/zh-CN/assets/images/jd01-47257e8bb0b14785f854db959cdfd931.png" width="871" height="600" class="img_ev3q"></p><p>EasyOLAP Doris 监控面板展示</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="03-easyolap-doris-主备双流设计"><strong>03 EasyOLAP Doris 主备双流设计</strong><a class="hash-link" href="#03-easyolap-doris-主备双流设计" title="标题的直接链接">​</a></h3><p>EasyOLAP Doris 为了保障 0 级业务在大促期间服务的稳定性，采取了主备集群双写的方式。当其中一个集群出现抖动或者数据存在延迟的情况，用户可以自主地快速切换到另一个集群，尽可能的减少集群抖动给业务带来的影响。</p><p><img loading="lazy" alt="03 EasyOLAP Doris Primary-Secondary Dual Stream Design" src="/zh-CN/assets/images/jd02-a6a4279c0c33a25862e89b56e7c986a7.png" width="1080" height="669" class="img_ev3q"></p><p>EasyOLAP Doris 主备双流设计</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="04-easyolap-doris-动态分区管理"><strong>04 EasyOLAP Doris 动态分区管理</strong><a class="hash-link" href="#04-easyolap-doris-动态分区管理" title="标题的直接链接">​</a></h3><p>京东 OLAP 团队分析需求之后，对 Doris 做了一定的定制化开发，其中就涉及到动态分区管理功能。尽管社区版本已经拥有动态分区的功能，但是该功能无法保留指定时间的分区。针对京东集团的特点，我们对指定时间的历史数据进行了留存，比如 618 和 11.11 期间的数据，不会因为动态分区而被删除。</p><p>动态分区管理功能能够控制集群中存储的数据量，而且方便了业务方的使用，无需手动或使用额外代码来管理分区信息。</p><h1><strong>Doris 缓存机制</strong></h1><h3 class="anchor anchorWithStickyNavbar_LWe7" id="01-需求场景"><strong>01 需求场景</strong><a class="hash-link" href="#01-需求场景" title="标题的直接链接">​</a></h3><p>致力于不断提升用户体验，京东客服的数据分析追求极致的时效性。离线数据分析场景是写少读多，数据写入一次，多次频繁读取；实时数据分析场景，一部分数据是不更新的历史分区，一部分数据是处于更新的分区。在大部分的分析应用中，存在下述几种场景：</p><ul><li>高并发场景：Doris 较好的支持高并发，但是过高的 QPS 会引起集群抖动，且单个节点无法承载太高的 QPS ；</li><li>复杂查询：京东客服实时运营平台监控根据业务场景需展示多维复杂指标，丰富指标展示对应多种不同的查询，且数据源来自于多张表，虽然单个查询的响应时间在毫秒级别，但是整体的响应时间可能会到秒级别；</li><li>重复查询：如果没有防重刷机制，由于延迟或手误，重复刷新页面会导致提交大量重复的查询；</li></ul><p>针对上述场景，在应用层有解决方案——将查询结果放入到 Redis 中，缓存会周期性的刷新或者由用户手动刷新，但是也会存在一些问题：</p><ul><li>数据不一致：无法立即对数据的更新作出响应，用户接收到的结果可能是旧数据；</li><li>命中率低：如果数据实时性强，缓存频繁失效，则缓存的命中率低且系统的负载无法得缓解；</li><li>额外成本：引入外部组件，增加系统复杂度，增加额外成本。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="02-缓存机制简介"><strong>02 缓存机制简介</strong><a class="hash-link" href="#02-缓存机制简介" title="标题的直接链接">​</a></h3><p>在 EasyOLAP Doris 中，一共有三种不同类型 Cache。根据适用场景的不同，分别为 Result Cache、SQL Cache 和 Partition Cache 。三种缓存都可以通过 MySQL 客户端指令控制开关。</p><p>这三种缓存机制是可以共存的，即可以同时开启。查询时，查询分析器首先会判断是否开启了 Result Cache ，在 Result Cache 开启的情况下先从 Result Cache 中查找该查询是否存在缓存，如果存在缓存，直接取缓存的值返回给客户端；如果缓存失效或者不存在，则直接进行查询并将结果写入到缓存。缓存放在各个 FE 节点的内存中，以便快速读取。</p><p>SQL Cache 按照 SQL 的签名、查询的表的分区的 ID 和分区最新版本号来存储和获取缓存。这三者一起作为缓存的条件，其中一者发生变化，如 SQL 语句变化、数据更新之后分区版本号变化，都会无法命中缓存。在多表 Join 的情况下，其中一张表的分区更新，也会导致无法命中缓存。SQL Cache 更适合 T+1 更新的场景。</p><p>Partition Cache 是更细粒度的缓存机制。Partition Cache 主要是将一个查询根据分区并行拆分，拆分为只读分区和可更新分区，只读分区缓存，更新分区不缓存，相应的结果集也会生成 n 个，然后再将各个拆分后的子查询的结果合并。因此，如果查询 N 天的数据，数据更新最近的 D 天，每天只是日期范围不一样但相似的查询，就可以利用 Partition Cache ，只需要查询 D 个分区即可，其他部分都来自缓存，可以有效降低集群负载，缩短查询响应时间。</p><p>一个查询进入到 Doris，系统先会处理查询语句，并将该查询语句作为 Key，在执行查询语句之前，查询分析器能够自动选择最适合的缓存机制，以确保在最优的情况下，利用缓存机制来缩短查询相应时间。然后检查 Cache 中是否存在该查询结果，如果存在就获取缓存中的数据返回给客户端；如果没有缓存，则正常查询，并将该查询结果以 Value 的形式和该查询语句 Key 存储到缓存中。Result Cache 可以在高并发场景下发挥其作用，也可以保护集群资源不受重复的大查询的侵占。SQL Cache 更加适合 T+1 的场景，在分区更新不频繁以及 SQL 语句重复的情况下，效果很好。Partition Cache 是粒度最小的缓存。在查询语句查询一个时间段的数据时，查询语句会被拆分成多个子查询。在数据只写一个分区或者部分分区的情况下，能够缩短查询时间，节省集群资源。</p><p>为了更好的观察缓存的效果，相关指标已经加入到 Doris 的服务指标中，通过 Prometheus 和 Grafana 监控系统获取直观的监控数据。指标有不同种类的 Cache 的命中数量、不同种类的 Cache 命中率、 Cache 的内存大小等指标。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="03-缓存机制效果"><strong>03 缓存机制效果</strong><a class="hash-link" href="#03-缓存机制效果" title="标题的直接链接">​</a></h3><p>京东客服 Doris 主集群，11.11 期间在没有开启缓存时，部分业务就导致 CPU 的使用率达到 100% ；在开启 Result Cache 的情况下，CPU 使用率在 30%-40% 之间。缓存机制确保业务在高并发场景下，能够快速的得到查询结果，并很好的保护了集群资源。</p><h1><strong>Doris 在 2020 年 11.11 大促期间的优化</strong></h1><h3 class="anchor anchorWithStickyNavbar_LWe7" id="01-导入任务优化"><strong>01 导入任务优化</strong><a class="hash-link" href="#01-导入任务优化" title="标题的直接链接">​</a></h3><p>实时数据的导入一直是一个挑战。其中，保证数据实时性和导入稳定性是最重要的。为了能够更加直观的观察实时数据导入的情况，京东 OLAP 团队自主开发了 OLAP Exporter ，用于采集实时数据导入相关的指标，如导入速度、导入积压和暂停的任务等。通过导入速度和导入积压，可以判断一个实时导入任务的状态，如发现任务有积压的趋势，可以使用自主开发的采样工具，对实时任务进行采样分析。实时任务主要有三个阈值来控制任务的提交，分别是每批次最大处理时间间隔、每批次最大处理条数和每批次最大处理数据量，一个任务只要达到其中一个阈值，该任务就会被提交。通过增加日志，发现 FE 中的任务队列比较繁忙，所以，参数的调整主要都是将每批次最大处理条数和每批次最大处理数据量调大，然后根据业务的需求，调整每批次最大处理时间间隔，以保证数据的延迟在每批次最大处理时间间隔的两倍之内。通过采样工具，分析任务，不仅保证了数据的实时性，也保证了导入的稳定性。另外，我们也设置了告警，可以及时发现实时导入任务的积压以及导入任务的暂停等异常情况。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="02-监控指标优化"><strong>02 监控指标优化</strong><a class="hash-link" href="#02-监控指标优化" title="标题的直接链接">​</a></h3><p>监控指标主要分为两个部分，一个是机器层面指标部分，一个是业务层面指标部分。在整个监控面板里，详细的指标带来了全面的数据的同时，也增加了获取重要指标的难度。所以，为了更好的观察所有集群的重要指标，单独设立一个板块—— 11.11 重要指标汇总板块。板块中有 BE CPU 使用率、实时任务消费积压行数、TP99、QPS 等指标。指标数量不多，但是可以观测到所有集群的情况，这样可以免去在监控中频繁切换的麻烦。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="03-周边工具支持"><strong>03 周边工具支持</strong><a class="hash-link" href="#03-周边工具支持" title="标题的直接链接">​</a></h3><p>除了上述说到的采样工具和 OLAP Exporter ，京东 OLAP 团队还开发了一系列的 Doris 维护工具。</p><ol><li><p>导入采样工具：导入采样工具不仅可以采集实时导入的数据，而且还支持调整实时导入任务的参数，或者在实时导入任务暂停状态下，生成创建语句（包括最新的位点等信息）用于任务的迁移等操作。</p></li><li><p>大查询工具：大查询不仅会造成集群 BE CPU 使用率的抖动，还会导致其他查询响应时间变长。在有大查询工具之前，发现集群 CPU 出现抖动，需要去检查所有 FE 上的审计日志，然后再做统计，不仅浪费时间，而且不够直观。大查询工具就是为了解决上述的问题。当监控侧发现集群有抖动，就可以使用大查询工具，输入集群名和时间点，就可以得到该时间点下，不同业务的查询总数，时间超过 5 秒、 10 秒、 20 秒的查询个数，扫描量巨大的查询个数等，方便我们从不同的维度分析大查询。大查询的详细情况也将被保存在中间文件中，可以直接获取不同业务的大查询。整个过程只需要几十秒到一分钟就可以定位到正在发生的大查询并获取相应的查询语句，大大节约了时间和运维成本。</p></li><li><p>降级与恢复工具：为了确保 11.11 大促期间， 0 级业务的稳定性，在集群压力超过安全位的时候，需要对其他非 0 级业务做降级处理，待度过高峰期后，再一键恢复到降级前的设置。降级主要是降低业务的最大连接数、暂停非 0 级的实时导入任务等。这大大增加了操作的便捷性，提高了效率。</p></li><li><p>集群巡检工具：在 11.11 期间，集群的健康巡检是极其重要的。常规巡检包括双流业务的主备集群一致性检查，为了确保业务在一个集群出现问题的时候可以快速切换到另一个集群，就需要保证两个集群上的库表一致、数据量差异不大等；检查库表的副本数是否为 3 且检查集群是否存在不健康的 Tablet ；检查机器磁盘使用率、内存等机器层面的指标等。</p></li></ol><h1><strong>总结与展望</strong></h1><p>京东客服是在 2020 年年初开始引入 Doris 的，目前拥有一个独立集群，一个共享集群，是京东 OLAP 的资深用户。</p><p>在业务使用中也遇到了例如任务调度相关的、导入任务配置相关的和查询相关等问题，这也在推动京东 OLAP 团队更深入的了解 Doris 。我们计划推广使用物化视图来进一步提升查询的效率；使用 Bitmap 来支持 UV 等指标的精确去重操作；使用审计日志，更方便的统计大查询、慢查询；解决实时导入任务的调度问题，使导入任务更加高效稳定。除此之外，我们也计划优化建表、创建优质 Rollup 或物化视图以提升应用的流畅性，加速更多业务向 OLAP 平台靠拢，以提升应用的影响力。</p>]]></content:encoded>
            <category>最佳实践</category>
        </item>
        <item>
            <title><![CDATA[Apache Doris 在美团外卖实时数仓建设中的实践]]></title>
            <link>https://doris.apache.org/zh-CN/blog/meituan</link>
            <guid>/meituan</guid>
            <pubDate>Wed, 20 Jul 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[<!--]]></description>
            <content:encoded><![CDATA[<p><strong>导读：</strong>本文主要介绍一种通用的实时数仓构建的方法与实践。实时数仓以端到端低延迟、SQL 标准化、快速响应变化、数据统一为目标。在实践中，我们总结的最佳实践是：一个通用的实时生产平台 + 一个通用交互式实时分析引擎相互配合同时满足实时和准实时业务场景。两者合理分工，互相补充，形成易于开发、易于维护、效率最高的流水线，兼顾开发效率与生产成本，以较好的投入产出比满足业务多样需求。</p><h1><strong>实时场景</strong></h1><p>实时数据在美团外卖的场景是非常多的，主要有以下几点：</p><ul><li><p>运营层面：比如实时业务变化，实时营销效果，当日营业情况以及当日实时业务趋势分析等。</p></li><li><p>生产层面：比如实时系统是否可靠，系统是否稳定，实时监控系统的健康状况等。</p></li><li><p>C 端用户：比如搜索推荐排序，需要实时了解用户的想法，行为、特点，给用户推荐更加关注的内容。</p></li><li><p>风控侧：在外卖以及金融科技用的是非常多的，实时风险识别，反欺诈，异常交易等，都是大量应用实时数据的场景</p></li></ul><h1><strong>实时技术及架构</strong></h1><h3 class="anchor anchorWithStickyNavbar_LWe7" id="1实时计算技术选型"><strong>1.实时计算技术选型</strong><a class="hash-link" href="#1实时计算技术选型" title="标题的直接链接">​</a></h3><p>目前开源的实时技术比较多，比较通用的是 Storm、Spark Streaming 以及 Flink，具体要根据不同公司的业务情况进行选型。</p><p>美团外卖是依托美团整体的基础数据体系建设，从技术成熟度来讲，前几年用的是 Storm，Storm 当时在性能稳定性、可靠性以及扩展性上是无可替代的，随着 Flink 越来越成熟，从技术性能上以及框架设计优势上已经超越 Storm，从趋势来讲就像 Spark 替代 MR 一样，Storm 也会慢慢被 Flink 替代，当然从 Storm 迁移到 Flink 会有一个过程，我们目前有一些老的任务仍然在 Storm 上，也在不断推进任务迁移。</p><p>具体 Storm 和 Flink 的对比可以参考上图表格。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="2实时架构">2.<strong>实时架构</strong><a class="hash-link" href="#2实时架构" title="标题的直接链接">​</a></h3><p><strong>① Lambda 架构</strong></p><p>Lambda 架构是比较经典的架构，以前实时的场景不是很多，以离线为主，当附加了实时场景后，由于离线和实时的时效性不同，导致技术生态是不一样的。Lambda 架构相当于附加了一条实时生产链路，在应用层面进行一个整合，双路生产，各自独立。这在业务应用中也是顺理成章采用的一种方式。</p><p>双路生产会存在一些问题，比如加工逻辑 double，开发运维也会 double，资源同样会变成两个资源链路。因为存在以上问题，所以又演进了一个 Kappa 架构。</p><p><strong>② Kappa 架构</strong></p><p>Kappa 架构从架构设计来讲比较简单，生产统一，一套逻辑同时生产离线和实时。但是在实际应用场景有比较大的局限性，在业内直接用 Kappa 架构生产落地的案例不多见，且场景比较单一。这些问题在我们这边同样会遇到，我们也会有自己的一些思考，在后面会讲到。</p><h1><strong>业务痛点</strong></h1><p>在外卖业务上，我们也遇到了一些问题。</p><p>业务早期，为了满足业务需要，一般是拿到需求后 case by case 的先把需求完成，业务对于实时性要求是很高的，从时效性来说，没有进行中间层沉淀的机会，在这种场景下，一般是拿到业务逻辑直接嵌入，这是能想到的简单有效的方法，在业务发展初期这种开发模式比较常见。</p><p>如上图所示，拿到数据源后，会经过数据清洗，扩维，通过 Storm 或 Flink 进行业务逻辑处理，最后直接进行业务输出。把这个环节拆开来看，数据源端会重复引用相同的数据源，后面进行清洗、过滤、扩维等操作，都要重复做一遍，唯一不同的是业务的代码逻辑是不一样的，如果业务较少，这种模式还可以接受，但当后续业务量上去后，会出现谁开发谁运维的情况，维护工作量会越来越大，作业无法形成统一管理。而且所有人都在申请资源，导致资源成本急速膨胀，资源不能集约有效利用，因此要思考如何从整体来进行实时数据的建设。</p><h1><strong>数据特点与应用场景</strong></h1><p>那么如何来构建实时数仓呢？</p><p>首先要进行拆解，有哪些数据，有哪些场景，这些场景有哪些共同特点，对于外卖场景来说一共有两大类，日志类和业务类。</p><ul><li><p>日志类：数据量特别大，半结构化，嵌套比较深。日志类的数据有个很大的特点，日志流一旦形成是不会变的，通过埋点的方式收集平台所有的日志，统一进行采集分发，就像一颗树，树根非常大，推到前端应用的时候，相当于从树根到树枝分叉的过程（从 1 到 n 的分解过程），如果所有的业务都从根上找数据，看起来路径最短，但包袱太重，数据检索效率低。日志类数据一般用于生产监控和用户行为分析，时效性要求比较高，时间窗口一般是 5min 或 10min 或截止到当前的一个状态，主要的应用是实时大屏和实时特征，例如用户每一次点击行为都能够立刻感知到等需求。</p></li><li><p>业务类：主要是业务交易数据，业务系统一般是自成体系的，以 Binlog 日志的形式往下分发，业务系统都是事务型的，主要采用范式建模方式，特点是结构化的，主体非常清晰，但数据表较多，需要多表关联才能表达完整业务，因此是一个 n 到 1 的集成加工过程。</p></li></ul><p>业务类实时处理面临的几个难点：</p><ul><li><p>业务的多状态性：业务过程从开始到结束是不断变化的，比如从下单-&gt;支付-&gt;配送，业务库是在原始基础上进行变更的，Binlog 会产生很多变化的日志。而业务分析更加关注最终状态，由此产生数据回撤计算的问题，例如 10 点下单，13 点取消，但希望在 10 点减掉取消单。</p></li><li><p>业务集成：业务分析数据一般无法通过单一主体表达，往往是很多表进行关联，才能得到想要的信息，在实时流中进行数据的合流对齐，往往需要较大的缓存处理且复杂。</p></li><li><p>分析是批量的，处理过程是流式的：对单一数据，无法形成分析，因此分析对象一定是批量的，而数据加工是逐条的。</p></li></ul><p>日志类和业务类的场景一般是同时存在的，交织在一起，无论是 Lambda 架构还是 Kappa 架构，单一的应用都会有一些问题。因此针对场景来选择架构与实践才更有意义。</p><h1><strong>实时</strong>数仓架构设计</h1><h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-实时架构流批结合的探索"><strong>1. 实时架构：流批结合的探索</strong><a class="hash-link" href="#1-实时架构流批结合的探索" title="标题的直接链接">​</a></h3><p>基于以上问题，我们有自己的思考。通过流批结合的方式来应对不同的业务场景。</p><p>如上图所示，数据从日志统一采集到消息队列，再到数据流的 ETL 过程，作为基础数据流的建设是统一的。之后对于日志类实时特征，实时大屏类应用走实时流计算。对于 Binlog 类业务分析走实时 OLAP 批处理。</p><p>流式处理分析业务的痛点？对于范式业务，Storm 和 Flink 都需要很大的外存，来实现数据流之间的业务对齐，需要大量的计算资源。且由于外存的限制，必须进行窗口的限定策略，最终可能放弃一些数据。计算之后，一般是存到 Redis 里做查询支撑，且 KV 存储在应对分析类查询场景中也有较多局限。</p><p>实时 OLAP 怎么实现？有没有一种自带存储的实时计算引擎，当实时数据来了之后，可以灵活的在一定范围内自由计算，并且有一定的数据承载能力，同时支持分析查询响应呢？随着技术的发展，目前 MPP 引擎发展非常迅速，性能也在飞快提升，所以在这种场景下就有了一种新的可能。这里我们使用的是 Doris 引擎。</p><p>这种想法在业内也已经有实践，且成为一个重要探索方向。阿里基于 ADB 的实时 OLAP 方案等。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-实时数仓架构设计"><strong>2. 实时数仓架构设计</strong><a class="hash-link" href="#2-实时数仓架构设计" title="标题的直接链接">​</a></h3><p>从整个实时数仓架构来看，首先考虑的是如何管理所有的实时数据，资源如何有效整合，数据如何进行建设。</p><p>从方法论来讲，实时和离线是非常相似的，离线数仓早期的时候也是 case by case，当数据规模涨到一定量的时候才会考虑如何治理。分层是一种非常有效的数据治理方式，所以在实时数仓如何进行管理的问题上，首先考虑的也是分层的处理逻辑，具体如下：</p><ul><li><p>数据源：在数据源的层面，离线和实时在数据源是一致的，主要分为日志类和业务类，日志类又包括用户日志，DB 日志以及服务器日志等。</p></li><li><p>实时明细层：在明细层，为了解决重复建设的问题，要进行统一构建，利用离线数仓的模式，建设统一的基础明细数据层，按照主题进行管理，明细层的目的是给下游提供直接可用的数据，因此要对基础层进行统一的加工，比如清洗、过滤、扩维等。</p></li><li><p>汇总层：汇总层通过 Flink 或 Storm 的简洁算子直接可以算出结果，并且形成汇总指标池，所有的指标都统一在汇总层加工，所有人按照统一的规范管理建设，形成可复用的汇总结果。</p></li></ul><p>总结起来，从整个实时数仓的建设角度来讲，首先数据建设的层次化要先建出来，先搭框架，然后定规范，每一层加工到什么程度，每一层用什么样的方式，当规范定义出来后，便于在生产上进行标准化的加工。由于要保证时效性，设计的时候，层次不能太多，对于实时性要求比较高的场景，基本可以走上图左侧的数据流，对于批量处理的需求，可以从实时明细层导入到实时 OLAP 引擎里，基于 OLAP 引擎自身的计算和查询能力进行快速的回撤计算，如上图右侧的数据流。</p><h1><strong>实时平台化建设</strong></h1><p>架构确定之后，后面考虑的是如何进行平台化的建设，实时平台化建设完全附加于实时数仓管理之上进行的。</p><p>首先进行功能的抽象，把功能抽象成组件，这样就可以达到标准化的生产，系统化的保障就可以更深入的建设，对于基础加工层的清洗、过滤、合流、扩维、转换、加密、筛选等功能都可以抽象出来，基础层通过这种组件化的方式构建直接可用的数据结果流。这其中会有一个问题，用户的需求多样，满足了这个用户，如何兼容其他的用户，因此可能会出现冗余加工的情况，从存储来讲，实时数据不存历史，不会消耗过多的存储，这种冗余是可以接受的，通过冗余的方式可以提高生产效率，是一种空间换时间的思想应用。</p><p>通过基础层的加工，数据全部沉淀到 IDL 层，同时写到 OLAP 引擎的基础层，再往上是实时汇总层计算，基于 Storm、Flink 或 Doris，生产多维度的汇总指标，形成统一的汇总层，进行统一的存储分发。</p><p>当这些功能都有了以后，元数据管理，指标管理，数据安全性、SLA、数据质量等系统能力也会逐渐构建起来。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="1实时基础层功能">1.实时基础层功能<a class="hash-link" href="#1实时基础层功能" title="标题的直接链接">​</a></h3><p>实时基础层的建设要解决一些问题。</p><p>首先是一条流重复读的问题，一条 Binlog 打过来，是以 DB 包的形式存在的，用户可能只用其中一张表，如果大家都要用，可能存在所有人都要接这个流的问题。解决方案是可以按照不同的业务解构出来，还原到基础数据流层，根据业务的需要做成范式结构，按照数仓的建模方式进行集成化的主题建设。</p><p>其次要进行组件的封装，比如基础层的清洗、过滤、扩维等功能，通过一个很简单的表达入口，让用户将逻辑写出来。trans 环节是比较灵活的，比如从一个值转换成另外一个值，对于这种自定义逻辑表达，我们也开放了自定义组件，可以通过 Java 或 Python 开发自定义脚本，进行数据加工。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="2实时特征生产功能">2.<strong>实时特征生产功能</strong><a class="hash-link" href="#2实时特征生产功能" title="标题的直接链接">​</a></h3><p>特征生产可以通过 SQL 语法进行逻辑表达，底层进行逻辑的适配，透传到计算引擎，屏蔽用户对计算引擎的依赖。就像对于离线场景，目前大公司很少通过代码的方式开发，除非一些特别的 case，所以基本上可以通过 SQL 化的方式表达。</p><p>在功能层面，把指标管理的思想融合进去，原子指标、派生指标，标准计算口径，维度选择，窗口设置等操作都可以通过配置化的方式，这样可以统一解析生产逻辑，进行统一封装。</p><p>还有一个问题，同一个源，写了很多 SQL，每一次提交都会起一个数据流，比较浪费资源，我们的解决方案是，通过同一条流实现动态指标的生产，在不停服务的情况下可以动态添加指标。</p><p>所以在实时平台建设过程中，更多考虑的是如何更有效的利用资源，在哪些环节更能节约化的使用资源，这是在工程方面更多考虑的事情。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="3sla-建设">3.SLA 建设<a class="hash-link" href="#3sla-建设" title="标题的直接链接">​</a></h3><p>SLA 主要解决两个问题，一个是端到端的 SLA，一个是作业生产效率的 SLA，我们采用埋点+上报的方式，由于实时流比较大，埋点要尽量简单，不能埋太多的东西，能表达业务即可，每个作业的输出统一上报到 SLA 监控平台，通过统一接口的形式，在每一个作业点上报所需要的信息，最后能够统计到端到端的 SLA。</p><p>在实时生产中，由于链路非常长，无法控制所有链路，但是可以控制自己作业的效率，所以作业 SLA 也是必不可少的。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="4-实时-olap-方案">4. 实时 OLAP 方案<a class="hash-link" href="#4-实时-olap-方案" title="标题的直接链接">​</a></h3><p>问题：</p><ul><li><p>Binlog 业务还原复杂：业务变化很多，需要某个时间点的变化，因此需要进行排序，并且数据要存起来，这对于内存和 CPU 的资源消耗都是非常大的。</p></li><li><p>Binlog 业务关联复杂：流式计算里，流和流之间的关联，对于业务逻辑的表达是非常困难的。</p></li></ul><p>解决方案：</p><p>通过带计算能力的 OLAP 引擎来解决，不需要把一个流进行逻辑化映射，只需要解决数据实时稳定的入库问题。</p><p>我们这边采用的是 Doris 作为高性能的 OLAP 引擎，由于业务数据产生的结果和结果之间还需要进行衍生计算，Doris 可以利用 unique 模型或聚合模型快速还原业务，还原业务的同时还可以进行汇总层的聚合，也是为了复用而设计。应用层可以是物理的，也可以是逻辑化视图。</p><p>这种模式重在解决业务回撤计算，比如业务状态改变，需要在历史的某个点将值变更，这种场景用流计算的成本非常大，OLAP 模式可以很好的解决这个问题。</p><h1>实时应用案例</h1><p>最后通过一个案例说明，比如商家要根据用户历史下单数给用户优惠，商家需要看到历史下了多少单，历史 T+1 的数据要有，今天实时的数据也要有，这种场景是典型的 Lambda 架构，可以在 Doris 里设计一个分区表，一个是历史分区，一个是今日分区，历史分区可以通过离线的方式生产，今日指标可以通过实时的方式计算，写到今日分区里，查询的时候进行一个简单的汇总。</p><p>这种场景看起来比较简单，难点在于商家的量上来之后，很多简单的问题都会变的复杂，因此后面我们也会通过更多的业务输入，沉淀出更多的业务场景，抽象出来形成统一的生产方案和功能，以最小化的实时计算资源支撑多样化的业务需求，这也是未来需要达到的目的。</p><p>今天的分享就到这里，谢谢大家。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="嘉宾介绍">嘉宾介绍：<a class="hash-link" href="#嘉宾介绍" title="标题的直接链接">​</a></h3><p>朱良，5 年以上传统行业数仓建设经验，6 年互联网数仓经验，技术方向涉及离线，实时数仓治理，系统化能力建设，OLAP 系统及引擎，大数据相关技术，重点跟进 OLAP，实时技术前沿发展趋势。业务方向涉及即席查询，运营分析，策略报告产品，用户画像，人群推荐，实验评估等。</p>]]></content:encoded>
            <category>最佳实践</category>
        </item>
        <item>
            <title><![CDATA[Apache Doris 1.1 Release 版本正式发布]]></title>
            <link>https://doris.apache.org/zh-CN/blog/1.1 Release</link>
            <guid>/1.1 Release</guid>
            <pubDate>Thu, 14 Jul 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[<!--]]></description>
            <content:encoded><![CDATA[<p>亲爱的社区小伙伴们，我们很高兴地宣布，Apache Doris 在 2022 年 7 月 14 日迎来 1.1 Release 版本的正式发布！这是 Apache Doris 正式从 Apache 孵化器毕业后并成为 Apache 顶级项目后发布的第一个 Release 版本。在 1.1 版本中，有 90 位 Contributor 为 Apache Doris 提交了超过 450 项优化和修复，感谢每一个让 Apache Doris 变得更好的你！</p><p>在 1.1 版本中，<strong>我们实现了计算层和存储层的全面向量化、正式将向量化执行引擎作为稳定功能进行全面启用</strong>，所有查询默认通过向量化执行引擎来执行，<strong>性能较之前版本有 3-5 倍的巨大提升</strong>；增加了直接访问 Apache Iceberg 外部表的能力，支持对 Doris 和 Iceberg 中的数据进行联邦查询，<strong>扩展了 Apache Doris 在数据湖上的分析能力</strong>；在原有的 LZ4 基础上增加了 ZSTD 压缩算法，进一步提升了数据压缩率；<strong>修复了诸多之前版本存在的性能与稳定性问题</strong>，使系统稳定性得到大幅提升。欢迎大家下载使用。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="升级说明">升级说明<a class="hash-link" href="#升级说明" title="标题的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="向量化执行引擎默认开启">向量化执行引擎默认开启<a class="hash-link" href="#向量化执行引擎默认开启" title="标题的直接链接">​</a></h3><p>在 Apache Doris 1.0 版本中，我们引入了向量化执行引擎作为实验性功能。用户需要在执行 SQL 查询手工开启，通过 <code>set batch_size = 4096</code> 和 <code>set enable_vectorized_engine = true </code>配置 session 变量来开启向量化执行引擎。</p><p>在 1.1 版本中，我们正式将向量化执行引擎作为稳定功能进行了全面启用，session 变量<code>enable_vectorized_engine</code> 默认设置为 true，无需用户手工开启，所有查询默认通过向量化执行引擎来执行。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="be-二进制文件更名">BE 二进制文件更名<a class="hash-link" href="#be-二进制文件更名" title="标题的直接链接">​</a></h3><p>BE 二进制文件从原有的 palo_be 更名为 doris_be ，如果您以前依赖进程名称进行集群管理和其他操作，请注意修改相关脚本。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="segment-存储格式升级">Segment 存储格式升级<a class="hash-link" href="#segment-存储格式升级" title="标题的直接链接">​</a></h3><p>Apache Doris 早期版本的存储格式为 Segment V1，在 0.12 版本中我们实现了新的存储格式 Segment V2 ，引入了 Bitmap 索引、内存表、Page Cache、字典压缩以及延迟物化等诸多特性。从 0.13 版本开始，新建表的默认存储格式为 Segment V2，与此同时也保留了对 Segment V1 格式的兼容。</p><p>为了保证代码结构的可维护性、降低冗余历史代码带来的额外学习及开发成本，我们决定从下一个版本起不再支持 Segment v1 存储格式，预计在 Apache Doris 1.2 版本中将删除这部分代码，还请所有仍在使用 Segment V1 存储格式的用户务必在 1.1 版本中完成数据格式的转换，操作手册请参考以下链接：</p><p><a href="https://doris.apache.org/zh-CN/docs/1.0/administrator-guide/segment-v2-usage" target="_blank" rel="noopener noreferrer">https://doris.apache.org/zh-CN/docs/1.0/administrator-guide/segment-v2-usage
</a></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="正常升级">正常升级<a class="hash-link" href="#正常升级" title="标题的直接链接">​</a></h3><p>正常升级操作请按照官网上的集群升级文档进行滚动升级即可。</p><p><a href="https://doris.apache.org/zh-CN/docs/admin-manual/cluster-management/upgrade" target="_blank" rel="noopener noreferrer">https://doris.apache.org/zh-CN/docs/admin-manual/cluster-management/upgrade</a></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="重要功能">重要功能<a class="hash-link" href="#重要功能" title="标题的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持数据随机分布-实验性功能httpsgithubcomapachedorispull8259-8041">支持数据随机分布 <!-- -->[实验性功能][#8259]<!-- -->(<a href="https://github.com/apache/doris/pull/8259" target="_blank" rel="noopener noreferrer">https://github.com/apache/doris/pull/8259</a>) <a href="https://github.com/apache/doris/pull/8041" target="_blank" rel="noopener noreferrer">#8041</a><a class="hash-link" href="#支持数据随机分布-实验性功能httpsgithubcomapachedorispull8259-8041" title="标题的直接链接">​</a></h3><p>在某些场景中（例如日志分析类场景），用户可能无法找到一个合适的分桶键来避免数据倾斜，因此需要由系统提供额外的分布方式来解决数据倾斜的问题。</p><p>因此通过在建表时可以不指定具体分桶键，选择使用随机分布对数据进行分桶<code>DISTRIBUTED BY random BUCKET number</code>，数据导入时将会随机写入单个 Tablet ，以减少加载过程中的数据扇出，并减少资源开销、提升系统稳定性。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持创建-iceberg-外部表-实验性功能httpsgithubcomapachedorispull7391-7981-8179">支持创建 Iceberg 外部表 <!-- -->[实验性功能][#7391]<!-- -->(<a href="https://github.com/apache/doris/pull/7391" target="_blank" rel="noopener noreferrer">https://github.com/apache/doris/pull/7391</a>) <a href="https://github.com/apache/doris/pull/7981" target="_blank" rel="noopener noreferrer">#7981</a> <a href="https://github.com/apache/doris/pull/8179" target="_blank" rel="noopener noreferrer">#8179</a><a class="hash-link" href="#支持创建-iceberg-外部表-实验性功能httpsgithubcomapachedorispull7391-7981-8179" title="标题的直接链接">​</a></h3><p>Iceberg 外部表为 Apache Doris 提供了直接访问存储在 Iceberg 数据的能力。通过 Iceberg 外部表可以实现对本地存储和 Iceberg 存储的数据进行联邦查询，省去繁琐的数据加载工作、简化数据分析的系统架构，并进行更复杂的分析操作。</p><p>在 1.1 版本中，Apache Doris 支持了创建 Iceberg 外部表并查询数据，并支持通过 REFRESH 命令实现 Iceberg 数据库中所有表 Schema 的自动同步。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="增加-zstd-压缩算法-8923-9747">增加 ZSTD 压缩算法 <a href="https://github.com/apache/doris/pull/8923" target="_blank" rel="noopener noreferrer">#8923</a> <a href="https://github.com/apache/doris/pull/9747" target="_blank" rel="noopener noreferrer">#9747</a><a class="hash-link" href="#增加-zstd-压缩算法-8923-9747" title="标题的直接链接">​</a></h3><p>目前 Apache Doris 中数据压缩方法是系统统一指定的，默认为 LZ4。针对部分对数据存储成本敏感的场景，例如日志类场景，原有的数据压缩率需求无法得到满足。</p><p>在 1.1 版本中，用户建表时可以在表属性中设置<code>"compression"="zstd"</code> 将压缩方法指定为 ZSTD。在 25GB 1.1 亿行的文本日志测试数据中，<strong>最高获得了近 10 倍的压缩率、较原有压缩率提升了 53%，从磁盘读取数据并进行解压缩的速度提升了 30%</strong> 。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="功能优化">功能优化<a class="hash-link" href="#功能优化" title="标题的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="更全面的向量化支持"><strong>更全面的向量化支持</strong><a class="hash-link" href="#更全面的向量化支持" title="标题的直接链接">​</a></h3><p>在 1.1 版本中，我们实现了计算层和存储层的全面向量化，包括：</p><ul><li><p>实现了所有内置函数的向量化</p></li><li><p>存储层实现向量化，并支持了低基数字符串列的字典优化</p></li><li><p>优化并解决了向量化引擎的大量性能和稳定性问题。</p></li></ul><p>我们对 Apache Doris 1.1 版本与 0.15 版本分别在 SSB 和 TPC-H 标准测试数据集上进行了性能测试：</p><ul><li><p>在 SSB 测试数据集的全部 13 个 SQL 上，1.1 版本均优于 0.15 版本，整体性能约提升了 3 倍，解决了 1.0 版本中存在的部分场景性能劣化问题；</p></li><li><p>在 TPC-H 测试数据集的全部 22 个 SQL 上，1.1 版本均优于 0.15 版本，整体性能约提升了 4.5 倍，部分场景性能达到了十余倍的提升；</p></li></ul><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/edb59781b0f74ff08821467f23a63bad~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p align="center">SSB 测试数据集</p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e34377054f4448b3b367789a391f2122~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p align="center">TPC-H 测试数据集</p><p><strong>性能测试报告：</strong></p><p><a href="https://doris.apache.org/zh-CN/docs/benchmark/ssb" target="_blank" rel="noopener noreferrer">https://doris.apache.org/zh-CN/docs/benchmark/ssb</a></p><p><a href="https://doris.apache.org/zh-CN/docs/benchmark/tpch" target="_blank" rel="noopener noreferrer">https://doris.apache.org/zh-CN/docs/benchmark/tpch</a></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="compaction-逻辑优化与实时性保证-10153">Compaction 逻辑优化与实时性保证 <a href="https://github.com/apache/doris/pull/10153" target="_blank" rel="noopener noreferrer">#10153</a><a class="hash-link" href="#compaction-逻辑优化与实时性保证-10153" title="标题的直接链接">​</a></h3><p>在 Apache Doris 中每次 Commit 都会产生一个数据版本，在高并发写入场景下，容易出现因数据版本过多且 Compaction 不及时而导致的 -235 错误，同时查询性能也会随之下降。</p><p>在 1.1 版本中我们引入了 QuickCompaction，增加了主动触发式的 Compaction 检查，在数据版本增加的时候主动触发 Compaction，同时通过提升分片元信息扫描的能力，快速发现数据版本过多的分片并触发 Compaction。通过主动式触发加被动式扫描的方式，彻底解决数据合并的实时性问题。</p><p>同时，针对高频的小文件 Cumulative Compaction，实现了 Compaction 任务的调度隔离，防止重量级的 Base Compaction 对新增数据的合并造成影响。</p><p>最后，针对小文件合并，优化了小文件合并的策略，采用梯度合并的方式，每次参与合并的文件都属于同一个数据量级，防止大小差别很大的版本进行合并，逐渐有层次的合并，减少单个文件参与合并的次数，能够大幅地节省系统的 CPU 消耗。</p><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a6d5c50f16a048f3ab27357bc97b7461~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><p>在数据上游维持每秒 10w 的写入频率时（20 个并发写入任务、每个作业 5000 行、 Checkpoint 间隔 1s），1.1 版本表现如下：</p><ul><li>数据快速合并：Tablet 数据版本维持在 50 以下，Compaction Score 稳定。相较于之前版本高并发写入时频繁出现的 -235 问题，<strong>Compaction 合并效率有 10 倍以上的提升</strong>。</li></ul><ul><li>CPU 资源消耗显著降低：针对小文件 Compaction 进行了策略优化，在上述高并发写入场景下，<strong>CPU 资源消耗降低 25%</strong> ；</li></ul><ul><li>查询耗时稳定：提升了数据整体有序性，大幅降低查询耗时的波动性，<strong>高并发写入时的查询耗时与仅查询时持平</strong>，查询性能较之前版本<strong>有 3-4 倍提升</strong>。</li></ul><p><img loading="lazy" src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1c79ee9efba0416d81cc7bed1a349fdf~tplv-k3u1fbpfcp-zoom-1.image" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="parquet-和-orc-文件的读取效率优化-9472">Parquet 和 ORC 文件的读取效率优化 <a href="https://github.com/apache/doris/pull/9472" target="_blank" rel="noopener noreferrer">#9472</a><a class="hash-link" href="#parquet-和-orc-文件的读取效率优化-9472" title="标题的直接链接">​</a></h3><p>通过调整 Arrow 参数，利用 Arrow 的多线程读取能力来加速 Arrow 对每个 row_group 的读取，并修改成 SPSC 模型，通过预取来降低等待网络的代价。优化前后对 Parquet 文件导入的性能有 4 ～ 5 倍的提升。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="更安全的元数据-checkpoint-9180-9192">更安全的元数据 Checkpoint <a href="https://github.com/apache/doris/pull/9180" target="_blank" rel="noopener noreferrer">#9180</a> <a href="https://github.com/apache/doris/pull/9192" target="_blank" rel="noopener noreferrer">#9192</a><a class="hash-link" href="#更安全的元数据-checkpoint-9180-9192" title="标题的直接链接">​</a></h3><p>通过对元数据检查点后生成的 image 文件进行双重检查和保留历史 image 文件的功能，解决了 image 文件错误导致的元数据损坏问题。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="bug-修复">Bug 修复<a class="hash-link" href="#bug-修复" title="标题的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="修复由于缺少数据版本而无法查询数据的问题严重9267-9266">修复由于缺少数据版本而无法查询数据的问题。（严重）<a href="https://github.com/apache/doris/pull/9267" target="_blank" rel="noopener noreferrer">#9267</a> <a href="https://github.com/apache/doris/pull/9266" target="_blank" rel="noopener noreferrer">#9266</a><a class="hash-link" href="#修复由于缺少数据版本而无法查询数据的问题严重9267-9266" title="标题的直接链接">​</a></h3><p>问题描述：<code>failed to initialize storage reader. tablet=924991.xxxx, res=-214, backend=xxxx</code></p><p>该问题是在版本 1.0 中引入的，可能会导致多个副本的数据版本丢失。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="解决了资源隔离对加载任务的资源使用限制无效的问题中等9492">解决了资源隔离对加载任务的资源使用限制无效的问题（中等）<a href="https://github.com/apache/doris/pull/9492" target="_blank" rel="noopener noreferrer">#9492</a><a class="hash-link" href="#解决了资源隔离对加载任务的资源使用限制无效的问题中等9492" title="标题的直接链接">​</a></h3><p>在 1.1 版本中， Broker Load 和 Routine Load 将使用具有指定资源标记的 BE 节点进行加载。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="修复使用-http-brpc-超过-2gb-传输网络数据包导致数据传输错误的问题中等9770">修复使用 HTTP BRPC 超过 2GB 传输网络数据包导致数据传输错误的问题（中等）<a href="https://github.com/apache/doris/pull/9770" target="_blank" rel="noopener noreferrer">#9770</a><a class="hash-link" href="#修复使用-http-brpc-超过-2gb-传输网络数据包导致数据传输错误的问题中等9770" title="标题的直接链接">​</a></h3><p>在以前的版本中，当通过 BRPC 在后端之间传输的数据超过 2GB 时，可能会导致数据传输错误。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="其他">其他<a class="hash-link" href="#其他" title="标题的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="禁用-mini-load">禁用 Mini Load<a class="hash-link" href="#禁用-mini-load" title="标题的直接链接">​</a></h3><p>Mini Load 与 Stream Load 的导入实现方式完全一致，都是通过 HTTP 协议提交和传输数据，在导入功能支持上 Stream Load 更加完备。</p><p>在 1.1 版本中，默认情况下 Mini Load 接口 <code>/_load</code> 将处于禁用状态，请统一使用 Stream Load 来替换 Mini Load。您也可以通过关闭 FE 配置项 <code>disable_mini_load</code> 来重新启用 Mini Load 接口。在版本 1.2 中，将彻底删除 Mini Load 。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="完全禁用-segmentv1-存储格式">完全禁用 SegmentV1 存储格式<a class="hash-link" href="#完全禁用-segmentv1-存储格式" title="标题的直接链接">​</a></h3><p>在 1.1 版本中将不再允许新创建 SegmentV1 存储格式的数据，现有数据仍可以继续正常访问。</p><p>您可以使用 ADMIN SHOW TABLET STORAGE FORMAT 语句检查集群中是否仍然存在 SegmentV1 格式的数据，如果存在请务必通过数据转换命令转换为 SegmentV2。</p><p>在 Apache Doris 1.2 版本中不再支持对 Segment V1 数据的访问，同时 Segment V1 代码将被彻底删除。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="限制-string-类型的最大长度-8567">限制 String 类型的最大长度 <a href="https://github.com/apache/doris/pull/8567" target="_blank" rel="noopener noreferrer">#8567</a><a class="hash-link" href="#限制-string-类型的最大长度-8567" title="标题的直接链接">​</a></h3><p>String 类型是 Apache Doris 在 0.15 版本中引入的新数据类型，在过去 String 类型的最大长度允许为 2GB。</p><p>在 1.1 版本中，我们将 String 类型的最大长度限制为 1 MB，超过此长度的字符串无法再写入，同时不再支持将 String 类型用作表的 Key 列、分区列以及分桶列。</p><p>已写入的字符串类型可以正常访问。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="修复-fastjson-相关漏洞-9763">修复 fastjson 相关漏洞 <a href="https://github.com/apache/doris/pull/9763" target="_blank" rel="noopener noreferrer">#9763</a><a class="hash-link" href="#修复-fastjson-相关漏洞-9763" title="标题的直接链接">​</a></h3><p>对 Canal 版本进行更新以修复 fastjson 安全漏洞</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="添加了-admin-diagnose-tablet-命令-8839">添加了 ADMIN DIAGNOSE TABLET 命令 <a href="https://github.com/apache/doris/pull/8839" target="_blank" rel="noopener noreferrer">#8839</a><a class="hash-link" href="#添加了-admin-diagnose-tablet-命令-8839" title="标题的直接链接">​</a></h3><p>通过 ADMIN DIAGNOSE TABLET tablet_id 命令可以快速诊断指定 Tablet 的问题。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="下载使用">下载使用<a class="hash-link" href="#下载使用" title="标题的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="下载链接">下载链接<a class="hash-link" href="#下载链接" title="标题的直接链接">​</a></h3><p><a href="https://doris.apache.org/zh-CN/download" target="_blank" rel="noopener noreferrer">https://doris.apache.org/zh-CN/download</a></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="升级说明-1">升级说明<a class="hash-link" href="#升级说明-1" title="标题的直接链接">​</a></h3><p>您可以从 Apache Doris 1.0 Release 版本和 1.0.x 发行版本升级到 1.1 Release 版本，升级过程请官网参考文档。如果您当前是 0.15 Release 版本或 0.15.x 发行版本，可跳过 1.0 版本直接升级至 1.1。</p><p>[https://doris.apache.org/zh-CN/docs/admin-manual/cluster-management/upgrade]<!-- -->(<a href="https://doris.apache.org/zh-CN/docs/admin-manual/cluster-management/upgrade" target="_blank" rel="noopener noreferrer">https://doris.apache.org/zh-CN/docs/admin-manual/cluster-management/upgrade</a></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="意见反馈">意见反馈<a class="hash-link" href="#意见反馈" title="标题的直接链接">​</a></h3><p>如果您遇到任何使用上的问题，欢迎随时通过 GitHub Discussion 论坛或者 Dev 邮件组与我们取得联系。</p><p>GitHub 论坛：<a href="https://github.com/apache/incubator-doris/discussions" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-doris/discussions</a></p><p>Dev 邮件组：<a href="/zh-CN/blog/dev@doris.apache.org">dev@doris.apache.org</a></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="致谢">致谢<a class="hash-link" href="#致谢" title="标题的直接链接">​</a></h2><p>Apache Doris 1.1 Release 版本的发布离不开所有社区用户的支持，在此向所有参与版本设计、开发、测试、讨论的社区贡献者们表示感谢，他们分别是：</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@adonis0147</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@airborne12</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@amosbird</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@aopangzi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@arthuryangcs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@awakeljw</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@BePPPower</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@BiteTheDDDDt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@bridgeDream</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@caiconghui</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@cambyzju</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@ccoffline</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@chenlinzhong</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@daikon12</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@DarvenDuan</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@dataalive</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@dataroaring</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@deardeng</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Doris-Extras</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@emerkfu</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@EmmyMiao87</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@englefly</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Gabriel39</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@GoGoWen</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@gtchaos</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@HappenLee</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@hello-stephen</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Henry2SS</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@hewei-nju</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@hf200012</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@jacktengg</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@jackwener</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Jibing-Li</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@JNSimba</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@kangshisen</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Kikyou1997</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@kylinmac</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Lchangliang</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@leo65535</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@liaoxin01</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@liutang123</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@lovingfeel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@luozenglin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@luwei16</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@luzhijing</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@mklzl</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@morningman</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@morrySnow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@nextdreamblue</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Nivane</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@pengxiangyu</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@qidaye</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@qzsee</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@SaintBacchus</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@SleepyBear96</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@smallhibiscus</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@spaces-X</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@stalary</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@starocean999</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@steadyBoy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@SWJTU-ZhangLei</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Tanya-W</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@tarepanda1024</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@tianhui5</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Userwhite</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@wangbo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@wangyf0555</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@weizuo93</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@whutpencil</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@wsjz</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@wunan1210</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xiaokang</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xinyiZzz</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xlwh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xy720</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@yangzhg</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Yankee24</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@yiguolei</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@yinzhijian</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@yixiutt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zbtzbtzbt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zenoyang</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zhangstar333</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zhangyifan27</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zhannngchen</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zhengshengjun</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zhengshiJ</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zingdle</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zuochunwei</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zy-kkk</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>]]></content:encoded>
            <category>版本发布</category>
        </item>
        <item>
            <title><![CDATA[开源实时分析型数据库 Apache Doris 正式成为顶级项目]]></title>
            <link>https://doris.apache.org/zh-CN/blog/Annoucing</link>
            <guid>/Annoucing</guid>
            <pubDate>Thu, 16 Jun 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[<!--]]></description>
            <content:encoded><![CDATA[<p>Apache Doris 是一个基于 MPP 的现代化、高性能、实时的分析型数据库，以极速易用的特点被人们所熟知，仅需亚秒级响应时间即可返回海量数据下的查询结果，不仅可以支持高并发的点查询场景，也能支持高吞吐的复杂分析场景。基于此，Apache Doris 在多维报表、用户画像、即席查询、实时大屏等诸多业务领域都能得到很好应用。</p><p>Apache Doris 最早是诞生于百度内部广告报表业务的 Palo 项目，2017 年正式对外开源，2018 年 7 月由百度捐赠给 Apache 基金会进行孵化，之后在 Apache 导师的指导下由孵化器项目管理委员会成员进行孵化和运营。</p><p>我们很自豪 Doris 能够顺利从 Apache 孵化器毕业，这是一个重要的里程碑。在整个孵化阶段，依靠 Apache 理念的指导和孵化器导师的帮助，我们学会了如何以 Apache 的方式去发展我们的项目与社区，也在这一进程中获得了巨大的成长。</p><p>目前 Apache Doris 社区已经聚集了来自不同行业近百家企业的 300 余位贡献者，并且每月活跃贡献者人数也接近 100 位。在孵化期间，Apache Doris 一共发布了 8 个重要版本，完成了包括存储引擎升级、向量化执行引擎等诸多重大功能，并正式发布了 1.0 版本。正是依靠这些来自开源贡献者的力量，才使得 Apache Doris 取得了今天的成绩。</p><p>与此同时，Apache Doris 如今在中国乃至全球范围内都拥有着极为广泛的用户群体，截止目前， Apache Doris 已经在全球超过 500 家企业的生产环境中得到应用，在中国市值或估值排行前 50 的互联网公司中，有超过 80% 长期使用 Apache Doris，包括百度、美团、小米、京东、字节跳动、腾讯、快手、网易、微博、新浪、360 等知名公司。同时在一些传统行业如金融、能源、制造、电信等领域也有着丰富的应用。</p><p>你可以基于 Apache Doris 快速构建一个简单易用并且性能强大的数据分析平台，非常易于上手，所需要付出的学习成本非常低。并且 Apache Doris 的分布式架构非常简洁，可以极大降低系统运维的工作量，这也是越来越多用户选择 Apache Doris 的关键因素。</p><p>作为一款成熟的分析型数据库项目，Apache Doris 有以下优势：</p><ul><li><p>性能优异：自带高效的列式存储引擎，减少数据扫描量的同时还实现了超高的数据压缩比。同时 Doris 还提供了丰富的索引结构来加速数据读取与过滤，利用分区分桶裁剪功能，Doris 可以支持在线服务业务的超高并发，单节点最高可支持上千 QPS。更进一步，Apache Doris 结合了向量化执行引擎来充分发挥现代化 CPU 并行计算能力，辅以智能物化视图技术实现预聚合加速，并可以通过查询优化器同时进行基于规划和基于代价的查询优化。通过上述多种方式，实现了极致的查询性能。</p></li><li><p>简单易用：支持标准 ANSI SQL 语法，包括单表聚合、排序、过滤和多表 Join、子查询等，还支持窗口函数、Grouping Set 等复杂 SQL 语法，同时用户可以通过 UDF 和 UDAF 等自定义函数来拓展系统功能。除此以外，Apache Doris 还实现了 MySQL 协议兼容，用户可以通过各类客户端工具来访问 Doris，并支持与 BI 工具的无缝对接。</p></li><li><p>架构精简：系统只有两个 Frontend（FE）和 Backend（BE）两个模块，其中 FE 节点负责用户请求的接入、查询计划的解析、元数据存储及集群管理等工作，BE 节点负责数据存储和查询计划的执行，自身就是一个完备的分布式数据库管理系统，用户无需安装任何第三方管控组件即可运行起 Apache Doris 集群，并且部署和升级过程都非常简易。同时，任一模块都可以支持横向拓展，集群最高可以拓展到数百个节点，支持存储超过 10PB 的超大规模数据。</p></li><li><p>稳定可靠：支持数据多副本存储，集群具备自愈功能，自身的分布式管理框架可以自动管理数据副本的分布、修复和均衡，副本损坏时系统可以自动感知并进行修复。节点扩容时，仅需一条 SQL 命令即可完成，数据分片会自动在节点间均衡，无需人工干预或操作。无论是扩容、缩容、单节点故障还是在升级过程中，系统都无需停止运行，可正常提供稳定可靠的在线服务。</p></li><li><p>生态丰富：提供丰富的数据同步方式，支持快速加载来自本地、Hadoop、Flink、Spark、Kafka、SeaTunnel 等系统中的数据，也可以直接访问 MySQL、PostgreSQL、Oracle、S3、Hive、Iceberg、Elasticsearch 等系统中的数据而无需数据复制。同时存储在 Doris 中的数据也可以被 Spark、Flink 读取，并且可以输出给上游数据应用进行展示分析。</p></li></ul><p>毕业不是最终目标，它是新征程的起点。在过去，我们发起 Doris 的目标是为更多人提供体验更佳的数据分析工具、解决他们数据分析的难题。成为 Apache 顶级项目一方面是对 Apache Doris 社区过去所有贡献者一直以来辛勤工作的肯定，另一方面也意味着我们在 Apache Way 的指引下建立了一个强大的、繁荣的、可持续发展的开源社区。未来我们将会继续以 Apache 方式运作社区，相信会吸引到更多优秀的开源贡献者参与社区中来，社区也会在所有贡献者的帮助下得到进一步成长。</p><p>Apache Doris 后续将开展更多富有挑战且有意义的工作，包括新的查询优化器、对湖仓一体化的支持，以及面向云上基础设施的架构演进等等。欢迎更多的开源技术爱好者加入 Apache Doris 的社区，携手共成长。</p><p>我们再次由衷地感谢所有参与建设 Apache Doris 社区的贡献者们，以及所有使用 Apache Doris 并不断提出改进建议的用户们。同时也感谢一路走来，不断鼓励、支持和帮助过我们的孵化器导师、IPMC 成员以及各个开源项目社区的朋友们。</p><p><strong>Apache Doris GitHub：</strong></p><p><a href="https://github.com/apache/doris" target="_blank" rel="noopener noreferrer">https://github.com/apache/doris</a></p><p><strong>Apache Doris website:</strong></p><p><a href="http://doris.apache.org" target="_blank" rel="noopener noreferrer">http://doris.apache.org</a></p><p><strong>Please contact us via:</strong></p><p><a href="/zh-CN/blog/dev@doris.apache.org.">dev@doris.apache.org.</a></p><p><strong>See How to subscribe:</strong></p><p><a href="http://doris.apache.org/community/subscribe-mail-list.html" target="_blank" rel="noopener noreferrer">http://doris.apache.org/community/subscribe-mail-list.html</a></p>]]></content:encoded>
            <category>重大新闻</category>
        </item>
        <item>
            <title><![CDATA[[Doris 发版通告] Apache Doris(Incubating) 1.0.0 Release]]></title>
            <link>https://doris.apache.org/zh-CN/blog/release-note-1.0.0</link>
            <guid>/release-note-1.0.0</guid>
            <pubDate>Mon, 18 Apr 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[<!--]]></description>
            <content:encoded><![CDATA[<h1>Apache Doris(Incubating) 1.0.0 Release</h1><p>亲爱的社区小伙伴们，历时数月，我们很高兴地宣布，Apache Doris (incubating) 于 2022 年 4 月 18 日迎来了 1.0 Release 版本的正式发布！<strong>这是 Apache Doris 在进入 Apache 基金会孵化以来的第一个 1 位版本，也是迄今为止对 Apache Doris 核心代码重构幅度最大的一个版本<!-- -->*<!-- -->*</strong>！<strong>有 </strong>114 位 Contributor<strong> 为 Apache Doris 提交了</strong>超过 660 项优化和修复<!-- -->*<!-- -->*<!-- -->，感谢每一个让 Apache Doris 变得更好的你！</p><p>在 1.0 版本中，我们引入了向量化执行引擎、Hive 外部表、Lateral View 语法及 Table Function 表函数、Z-Order 数据索引、Apache SeaTunnel 插件等重要功能，增加了对 Flink CDC 同步更新和删除数据的支持，优化了诸多数据导入和查询过程中的问题，对 Apache Doris 的查询性能、易用性、稳定性等多方特效进行了全面加强，欢迎大家下载使用！点击文末“<strong>阅读原文</strong>”即可直接前往下载地址。</p><p>每一个不曾发版的日子，背后都有无数贡献者枕戈待旦，不敢停歇半分。在此我们尤其要感谢来自<strong>向量化执行引擎、查询优化器、可视化运维平台 等 SIG （专项兴趣小组）的小伙伴</strong>。自 2021 年 8 月 Apache Doris 社区 SIG 小组成立以来，<strong>来自百度、美团、小米、京东、蜀海、字节跳动、腾讯、网易、阿里巴巴、PingCAP、Nebula Graph 等十余家公司的数十名贡献者</strong>作为首批成员加入到 SIG 中，第一次以专项小组的开源协作形式完成了向量化执行引擎、查询优化器、 Doris Manager 可视化监控运维平台等如此重大功能的开发，<strong>历时半年以上、开展技术调研和分享数十次、召开远程会议近百次、累计提交 Commits 多达数百个、涉及代码行数高达十余万行</strong>，正是因为有他们的贡献，才有 1.0 版本的问世，让我们再次对他们的辛勤付出表示最真诚的感谢！</p><p>与此同时，Apache Doris 的贡献者数量已超过 300 人，每月活跃的贡献者数量超过了 60 人，近几周平均每周提交的 Commits 数量也超过 80，社区聚集的开发者规模及活跃度已经有了极大的提升。我们十分期待有更多的小伙伴参与社区贡献中来，与我们一道把 Apache Doris 打造成全球顶级的分析型数据库，也期待所有小伙伴可以与我们一起收获宝贵的成长。如果你想参与社区，欢迎通过开发者邮箱 <a href="mailto:dev@doris.apache.org" target="_blank" rel="noopener noreferrer">dev@doris.apache.org</a> 与我们取得联系。</p><p>我们欢迎大家在使用过程中，有任何问题通过 GitHub Discussion 或者 Dev 邮件组与我们取得联系，也期待大家参与社区讨论和建设中 。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="重要更新">重要更新<a class="hash-link" href="#重要更新" title="标题的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="向量化执行引擎-experimental">向量化执行引擎 <!-- -->[Experimental]<a class="hash-link" href="#向量化执行引擎-experimental" title="标题的直接链接">​</a></h3><p>过去 Apache Doris 的 SQL 执行引擎是基于行式内存格式以及基于传统的火山模型进行设计的，在进行 SQL 算子与函数运算时存在非必要的开销，导致 Apache Doris 执行引擎的效率受限，并不适应现代 CPU 的体系结构。向量化执行引擎的目标是替换 Apache Doris 当前的行式 SQL 执行引擎，充分释放现代 CPU 的计算能力，突破在 SQL 执行引擎上的性能限制，发挥出极致的性能表现。</p><p>基于现代 CPU 的特点与火山模型的执行特点，向量化执行引擎重新设计了在列式存储系统的 SQL 执行引擎：</p><ul><li>重新组织内存的数据结构，用 Column 替换 Tuple，提高了计算时 Cache 亲和度，分支预测与预取内存的友好度</li><li>分批进行类型判断，在本次批次中都使用类型判断时确定的类型，将每一行类型判断的虚函数开销分摊到批量级别。</li><li>通过批级别的类型判断，消除了虚函数的调用，让编译器有函数内联以及 SIMD 优化的机会</li></ul><p>从而大大提高了 CPU 在 SQL 执行时的效率，提升了 SQL 查询的性能。</p><p>在 Apache Doris 1.0 版本中，通过 set batch_size = 4096 和 set enable_vectorized_engine = true 开启向量化执行引擎，多数情况下可显著提升查询性能。在 SSB 和 OnTime 标准测试数据集下，多表关联和宽列查询两大场景的整体性能分别有 3 倍和 2.6 倍的提升。</p><p><img loading="lazy" src="/zh-CN/assets/images/1.0.0-1-e7888e124fefa8bd38215dd9d4be4794.png" width="1080" height="697" class="img_ev3q"></p><p><img loading="lazy" src="/zh-CN/assets/images/1.0.0-2-d9e8be01f5ff99dd6e15fc33af4518fc.png" width="1080" height="819" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="lateral-view-语法-experimental">Lateral View 语法 <!-- -->[Experimental]<a class="hash-link" href="#lateral-view-语法-experimental" title="标题的直接链接">​</a></h3><p>通过 Lateral View 语法，我们可以使用 explod_bitmap 、explode_split、explode_jaon_array 等 Table Function 表函数，将 bitmap、String 或 Json Array 由一列展开成多行，以便后续可以对展开的数据进行进一步处理（如 Filter、Join 等）。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="hive-外表-experimental">Hive 外表 <!-- -->[Experimental]<a class="hash-link" href="#hive-外表-experimental" title="标题的直接链接">​</a></h3><p>Hive External Table 为用户提供了通过 Doris 直接访问 Hive 表的能力，外部表省去了 繁琐的数据导入工作，可以借助 Doris 本身 OLAP 的能力来解决 Hive 表的数据分析问题。当前版本支持将 Hive 数据源接入 Doris，并支持通过 Doris 与 Hive 数据源中的数据进行联邦查询，进行更加复杂的分析操作。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持-z-order-数据排序格式">支持 Z-Order 数据排序格式<a class="hash-link" href="#支持-z-order-数据排序格式" title="标题的直接链接">​</a></h3><p>Apache Doris 数据是按照前缀列排序存储的，因此在包含前缀查询条件时，可以在排序数据上进行快速的数据查找，但如果查询条件不是前缀列，则无法利用数据排序的特征进行快速数据查找。通过 Z-Order Indexing 可以解决上述问题，在 1.0 版本中我们增加了 Z-Order 数据排序格式，在看板类多列查询的场景中可以起到很好过滤效果，加速对非前缀列条件的过滤性能。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持-apache-seatunnelincubating插件">支持 Apache SeaTunnel（Incubating）插件<a class="hash-link" href="#支持-apache-seatunnelincubating插件" title="标题的直接链接">​</a></h3><p>Apache SeaTunnel 是一个高性能的分布式数据集成框架，架构于 Apache Spark 和 Apache Flink 之上。在 Apache Doris 1.0 版本中，我们增加了 SaeTunnel 插件，用户可以借助 Apache SeaTunnel 进行多数据源之间的同步和 ETL。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="新增函数">新增函数<a class="hash-link" href="#新增函数" title="标题的直接链接">​</a></h3><p>支持更多 bitmap 函数，具体可查看函数手册：</p><ul><li>bitmap_max</li><li>bitmap_and_not</li><li>bitmap_and_not_count</li><li>bitmap_has_all</li><li>bitmap_and_count</li><li>bitmap_or_count</li><li>bitmap_xor_count</li><li>bitmap_subset_limit</li><li>sub_bitmap</li></ul><p>支持国密算法 SM3/SM4；</p><blockquote><p><strong>注意</strong>：以上标记 <!-- -->[Experimental]<!-- --> 的功能为实验性功能，我们将会在后续版本中对以上功能进行持续优化和迭代，并后续版本中进一步完善。在使用过程中有任何问题或意见，欢迎随时与我们联系</p></blockquote><h3 class="anchor anchorWithStickyNavbar_LWe7" id="重要优化">重要优化<a class="hash-link" href="#重要优化" title="标题的直接链接">​</a></h3><h3 class="anchor anchorWithStickyNavbar_LWe7" id="功能优化">功能优化<a class="hash-link" href="#功能优化" title="标题的直接链接">​</a></h3><ul><li>降低大批量导入时，生成的 Segment 文件数量，以降低 Compaction 压力。</li><li>通过 BRPC 的 attachment 功能传输数据，以查询过程中的降低序列化和反序列化开销。</li><li>支持直接返回 HLL/BITMAP 类型的二进制数据，用于业务在外侧解析。</li><li>优化并降低 BRPC 出现 OVERCROWDED 和 NOT_CONNECTED 错误的概率，增强系统稳定性。</li><li>增强导入的容错性。</li><li>支持通过 Flink CDC 同步更新和删除数据。</li><li>支持自适应的 Runtime Filter。</li><li>显著降低 insert into 操作的内存占用</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="易用性改进">易用性改进<a class="hash-link" href="#易用性改进" title="标题的直接链接">​</a></h3><ul><li>Routine Load 支持显示当前 offset 延迟数量等状态。</li><li>FE audit log 中增加查询峰值内存使用量的统计。</li><li>Compaction URL 结果中增加缺失版本的信息，方便排查问题。</li><li>支持将 BE 标记为不可查询或不可导入，以快速屏蔽问题节点。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="重要-bug-修复">重要 Bug 修复<a class="hash-link" href="#重要-bug-修复" title="标题的直接链接">​</a></h3><ul><li>修复若干查询错误问题。</li><li>修复 Broker Load 若干调度逻辑问题。</li><li>修复 STREAM 关键词导致元数据无法加载的问题。</li><li>修复 Decommission 无法正确执行的问题。</li><li>修复部分情况下操作 Schema Change 操作可能出现 -102 错误的问题。</li><li>修复部分情况下使用 String 类型可能导致 BE 宕机的问题。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="其他">其他<a class="hash-link" href="#其他" title="标题的直接链接">​</a></h3><ul><li>增加 Minidump 功能；</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="更新日志">更新日志<a class="hash-link" href="#更新日志" title="标题的直接链接">​</a></h2><p>详细 Release Note 请查看链接：</p><p><a href="https://github.com/apache/incubator-doris/issues/8549" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-doris/issues/8549</a></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="致谢">致谢<a class="hash-link" href="#致谢" title="标题的直接链接">​</a></h2><p>Apache Doris(incubating) 1.0 Release 版本的发布离不开所有社区用户的支持，在此向所有参与版本设计、开发、测试、讨论的社区贡献者们表示感谢，他们分别是：</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@924060929</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@adonis0147</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Aiden-Dong</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@aihai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@airborne12</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Alibaba-HZY</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@amosbird</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@arthuryangcs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@awakeljw</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@bingzxy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@BiteTheDDDDt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@blackstar-baba</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@caiconghui</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@CalvinKirs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@cambyzju</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@caoliang-web</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@ccoffline</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@chaplinthink</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@chovy-3012</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@ChPi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@DarvenDuan</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@dataalive</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@dataroaring</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@dh-cloud</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@dohongdayi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@dongweizhao</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@drgnchan</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@e0c9</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@EmmyMiao87</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@englefly</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@eyesmoons</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@freemandealer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Gabriel39</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@gaodayue</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@GoGoWen</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Gongruixiao</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@gwdgithubnom</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@HappenLee</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Henry2SS</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@hf200012</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@htyoung</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@jacktengg</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@jackwener</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@JNSimba</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Keysluomo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@kezhenxu94</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@killxdcj</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@lihuigang</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@littleeleventhwolf</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@liutang123</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@liuzhuang2017</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@lonre</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@lovingfeel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@luozenglin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@luzhijing</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@MeiontheTop</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@mh-boy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@morningman</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@mrhhsg</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Myasuka</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@nimuyuhan</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@obobj</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@pengxiangyu</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@qidaye</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@qzsee</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@renzhimin7</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Royce33</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@SleepyBear96</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@smallhibiscus</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@sodamnsure</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@spaces-X</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@sparklezzz</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@stalary</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@steadyBoy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@tarepanda1024</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@THUMarkLau</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@tianhui5</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@tinkerrrr</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@ucasfl</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Userwhite</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@vinson0526</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@wangbo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@wangshuo128</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@wangyf0555</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@weajun</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@weizuo93</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@whutpencil</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@WindyGao</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@wunan1210</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xiaokang</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xiaokangguo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xiedeyantu</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xinghuayu007</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xingtanzjr</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xinyiZzz</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xtr1993</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xu20160924</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xuliuzhe</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xuzifu666</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@xy720</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@yangzhg</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@yiguolei</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@yinzhijian</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@yjant</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zbtzbtzbt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zenoyang</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zh0122</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zhangstar333</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zhannngchen</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zhengshengjun</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zhengshiJ</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@ZhikaiZuo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@ztgoto</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@zuochunwei</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>]]></content:encoded>
            <category>版本发布</category>
        </item>
        <item>
            <title><![CDATA[[Doris 发版通告] Apache Doris(Incubating) 0.15.0 Release]]></title>
            <link>https://doris.apache.org/zh-CN/blog/release-note-0.15.0</link>
            <guid>/release-note-0.15.0</guid>
            <pubDate>Mon, 29 Nov 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[<!--]]></description>
            <content:encoded><![CDATA[<h1>Apache Doris(Incubating) 0.15.0 Release</h1><p>亲爱的社区小伙伴们，历时数个月精心打磨，我们很高兴地宣布， Apache Doris(incubating) 于 2021 年 11 月 29 日迎来了 0.15.0 Release 版本的正式发布！有 99 位 Contributor 为 Apache Doris 提交了近 700 项优化和修复，在此我们也对所有贡献者表示最真诚的感激！</p><p>在 0.15.0 Release 版本中，我们增加了诸多新功能，对 Apache Doris 的查询性能、易用性、稳定性方面等进行了全面优化：新增资源划分和隔离功能，用户可以通过资源标签的方式将集群中的 BE 节点划分为资源组，实现对在线、离线业务的统一管理和资源隔离；增加了 Runtime Filter 及 Join Reorder 功能，对多表 Join 场景的查询效率进行了大幅提升，在 Star Schema Benchmark 测试数据集下有 2-10 倍的性能提升；新增导入方式 Binlog Load ，使 Doris 可以增量同步 MySQL 中对数据更新操作的 CDC ；支持 String 列类型，长度最大支持 2GB ；支持 List 分区功能，可以通过枚举值创建分区；支持 Unique Key 模型上的 Update 语句；Spark-Doris-Connector 支持数据写入 Doris ……还有更多重要特性，欢迎大家下载使用。</p><p>我们欢迎大家在使用过程中，有任何问题通过 GitHub Discussion 或者 Dev 邮件组与我们取得联系，也期待大家参与社区讨论和建设中 。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="重要更新">重要更新<a class="hash-link" href="#重要更新" title="标题的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="资源划分与隔离">资源划分与隔离<a class="hash-link" href="#资源划分与隔离" title="标题的直接链接">​</a></h3><p>用户可以通过资源标签的方式将一个 Doris 集群中的 BE 节点划分成多个资源组，从而可以进行在线、离线业务的统一管理和节点级别的资源隔离。
同时，还可以通过限制单个查询任务的 CPU、内存开销以及复杂度，来控制单个查询的资源开销，从而降低不同查询之间的资源抢占问题。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="性能优化">性能优化<a class="hash-link" href="#性能优化" title="标题的直接链接">​</a></h3><ul><li><p>Runtime Filter 功能通过使用 Join 算子中右表的 Join Key 列条件来过滤左表的数据，在大部分 Join 场景下可以显著提升查询效率。如在 Star Schema Benchmark ( TPCH 的精简测试集) 下可以获得 2-10 倍的性能提升。</p></li><li><p>Join Reorder 功能可以通过通过代价模型自动帮助调整 SQL 中 Join 的顺序，以帮助获得最优的 Join 效率。
可通过会话变量  <code>set enable_cost_based_join_reorder=true</code>  开启。</p></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="新增功能">新增功能<a class="hash-link" href="#新增功能" title="标题的直接链接">​</a></h3><ul><li>支持直接对接 Canal Server 同步 MySQL binlog 数据。</li><li>支持 String 列类型，最大支持 2GB 。</li><li>支持 List 分区功能，可以针对枚举值创建分区。</li><li>支持事务性 Insert 语句功能。可以通过 begin ; insert ; insert; ,... ; commit ; 的方式批量导入数据。</li><li>支持在 Unique Key 模型上的 Update 语句功能。可以在 Unique Key 模型表上执行 Update Set where 语句。</li><li>支持 SQL 阻塞名单功能。可以通过正则、Hash 值匹配等方式阻止部分 SQL 的执行。</li><li>支持 LDAP 登陆验证。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="拓展功能">拓展功能<a class="hash-link" href="#拓展功能" title="标题的直接链接">​</a></h3><ul><li>支持 Flink-Doris-Connector 。</li><li>支持 DataX doriswriter 插件。</li><li>Spark-Doris-Connector 支持数据写入 Doris 。</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="功能优化">功能优化<a class="hash-link" href="#功能优化" title="标题的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="查询">查询<a class="hash-link" href="#查询" title="标题的直接链接">​</a></h3><ul><li>支持在 SQL 查询规划阶段，利用 BE 的函数计算能力计算所有常量表达式。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="导入">导入<a class="hash-link" href="#导入" title="标题的直接链接">​</a></h3><ul><li>支持导入文本格式文件时，指定多字节行列分隔符或不可见分隔符。</li><li>支持通过 Stream Load 导入压缩格式文件。</li><li>Stream Load支持导入多行格式的 Json 数据。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="导出">导出<a class="hash-link" href="#导出" title="标题的直接链接">​</a></h3><ul><li>支持 Export 导出功能指定 where 过滤条件。支持导出文件使用多字节行列分隔符。支持导出到本地文件。</li><li>Export 导出功能支持仅导出指定的列。</li><li>支持通过 outfile 语句导出结果集到本地磁盘，并支持导出后写入导出成功的标记文件。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="易用性">易用性<a class="hash-link" href="#易用性" title="标题的直接链接">​</a></h3><ul><li>动态分区功能支持创建、保留指定的历史分区、支持自动冷热数据迁移设置。</li><li>支持在命令行使用可视化的树形结构展示查询、导入的计划和 Profile。</li><li>支持记录并查看 Stream Load 操作日志。</li><li>通过 Routine Load 消费 Kafka 数据时，可以指定时间点进行消费。</li><li>支持通过 show create routine load 功能导出 Routine Load 的创建语句。</li><li>支持通过 pause/resume all routine load 命令一键启停所有 Routine Load Job。</li><li>支持通过 alter routine load 语句修改 Routine Load 的 Broker List 和 Topic。</li><li>支持 create table as select 功能。</li><li>支持通过 alter table 命令修改列注释和表注释。</li><li>show tablet status 增加表创建时间、数据更新时间。</li><li>支持通过 show data skew 命令查看表的数据量分布，以排查数据倾斜问题。</li><li>支持通过 show/clean trash 命令查看 BE 文件回收站的磁盘占用情况并主动清除。</li><li>支持通过 show view 语句展示一个表被哪些视图所引用。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="新增函数">新增函数<a class="hash-link" href="#新增函数" title="标题的直接链接">​</a></h3><ul><li><code>bitmap_min</code>, <code>bit_length</code></li><li><code>yearweek</code>, <code>week</code>, <code>makedate</code></li><li><code>percentile</code> 精确百分位函数</li><li><code>json_array</code>，<code>json_object</code>，<code>json_quote</code></li><li>支持为 <code>AES_ENCRYPT</code> 和 <code>AES_DECRYPT</code> 函数创建自定义公钥。</li><li>支持通过 <code>create alias function</code> 创建函数别名来组合多个函数。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="其他">其他<a class="hash-link" href="#其他" title="标题的直接链接">​</a></h3><ul><li>支持访问 SSL 连接协议的ES外表。</li><li>支持在动态分区属性中指定热点分区的数量，热点分区将存储在 SSD 磁盘中。</li><li>支持通过 Broker Load 导入 Json 格式数据。</li><li>支持直接通过 libhdfs3 库访问 HDFS 进行数据的导入导出，而不需要 Broker 进程。</li><li>select into outfile 功能支持导出 Parquet 文件格式，并支持并行导出。</li><li>ODBC 外表支持 SQLServer。 </li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="致谢">致谢<a class="hash-link" href="#致谢" title="标题的直接链接">​</a></h2><p>Apache Doris(incubating) 0.15.0 Release 版本的发布离不开所有社区用户的支持，在此向所有参与版本设计、开发、测试、讨论的社区贡献者们表示感谢，他们分别是：</p><ul><li><a href="https://github.com/924060929" target="_blank" rel="noopener noreferrer">@924060929</a></li><li><a href="https://github.com/acelyc111" target="_blank" rel="noopener noreferrer">@acelyc111</a></li><li><a href="https://github.com/Aimiyoo" target="_blank" rel="noopener noreferrer">@Aimiyoo</a></li><li><a href="https://github.com/amosbird" target="_blank" rel="noopener noreferrer">@amosbird</a></li><li><a href="https://github.com/arthur-zhang" target="_blank" rel="noopener noreferrer">@arthur-zhang</a></li><li><a href="https://github.com/azurenake" target="_blank" rel="noopener noreferrer">@azurenake</a></li><li><a href="https://github.com/BiteTheDDDDt" target="_blank" rel="noopener noreferrer">@BiteTheDDDDt</a></li><li><a href="https://github.com/caiconghui" target="_blank" rel="noopener noreferrer">@caiconghui</a></li><li><a href="https://github.com/caneGuy" target="_blank" rel="noopener noreferrer">@caneGuy</a></li><li><a href="https://github.com/caoliang-web" target="_blank" rel="noopener noreferrer">@caoliang-web</a></li><li><a href="https://github.com/ccoffline" target="_blank" rel="noopener noreferrer">@ccoffline</a></li><li><a href="https://github.com/chaplinthink" target="_blank" rel="noopener noreferrer">@chaplinthink</a></li><li><a href="https://github.com/chovy-3012" target="_blank" rel="noopener noreferrer">@chovy-3012</a></li><li><a href="https://github.com/ChPi" target="_blank" rel="noopener noreferrer">@ChPi</a></li><li><a href="https://github.com/copperybean" target="_blank" rel="noopener noreferrer">@copperybean</a></li><li><a href="https://github.com/crazyleeyang" target="_blank" rel="noopener noreferrer">@crazyleeyang</a></li><li><a href="https://github.com/dh-cloud" target="_blank" rel="noopener noreferrer">@dh-cloud</a></li><li><a href="https://github.com/DinoZhang" target="_blank" rel="noopener noreferrer">@DinoZhang</a></li><li><a href="https://github.com/dixingxing0" target="_blank" rel="noopener noreferrer">@dixingxing0</a></li><li><a href="https://github.com/dohongdayi" target="_blank" rel="noopener noreferrer">@dohongdayi</a></li><li><a href="https://github.com/e0c9" target="_blank" rel="noopener noreferrer">@e0c9</a></li><li><a href="https://github.com/EmmyMiao87" target="_blank" rel="noopener noreferrer">@EmmyMiao87</a></li><li><a href="https://github.com/eyesmoons" target="_blank" rel="noopener noreferrer">@eyesmoons</a></li><li><a href="https://github.com/francisoliverlee" target="_blank" rel="noopener noreferrer">@francisoliverlee</a></li><li><a href="https://github.com/Gabriel39" target="_blank" rel="noopener noreferrer">@Gabriel39</a></li><li><a href="https://github.com/gaodayue" target="_blank" rel="noopener noreferrer">@gaodayue</a></li><li><a href="https://github.com/GoGoWen" target="_blank" rel="noopener noreferrer">@GoGoWen</a></li><li><a href="https://github.com/HappenLee" target="_blank" rel="noopener noreferrer">@HappenLee</a></li><li><a href="https://github.com/harveyyue" target="_blank" rel="noopener noreferrer">@harveyyue</a></li><li><a href="https://github.com/Henry2SS" target="_blank" rel="noopener noreferrer">@Henry2SS</a></li><li><a href="https://github.com/hf200012" target="_blank" rel="noopener noreferrer">@hf200012</a></li><li><a href="https://github.com/huangmengbin" target="_blank" rel="noopener noreferrer">@huangmengbin</a></li><li><a href="https://github.com/huozhanfeng" target="_blank" rel="noopener noreferrer">@huozhanfeng</a></li><li><a href="https://github.com/huzk8" target="_blank" rel="noopener noreferrer">@huzk8</a></li><li><a href="https://github.com/hxianshun" target="_blank" rel="noopener noreferrer">@hxianshun</a></li><li><a href="https://github.com/ikaruga4600" target="_blank" rel="noopener noreferrer">@ikaruga4600</a></li><li><a href="https://github.com/JameyWoo" target="_blank" rel="noopener noreferrer">@JameyWoo</a></li><li><a href="https://github.com/Jennifer88huang" target="_blank" rel="noopener noreferrer">@Jennifer88huang</a></li><li><a href="https://github.com/JinLiOnline" target="_blank" rel="noopener noreferrer">@JinLiOnline</a></li><li><a href="https://github.com/jinyuanlu" target="_blank" rel="noopener noreferrer">@jinyuanlu</a></li><li><a href="https://github.com/JNSimba" target="_blank" rel="noopener noreferrer">@JNSimba</a></li><li><a href="https://github.com/killxdcj" target="_blank" rel="noopener noreferrer">@killxdcj</a></li><li><a href="https://github.com/kuncle" target="_blank" rel="noopener noreferrer">@kuncle</a></li><li><a href="https://github.com/liutang123" target="_blank" rel="noopener noreferrer">@liutang123</a></li><li><a href="https://github.com/luozenglin" target="_blank" rel="noopener noreferrer">@luozenglin</a></li><li><a href="https://github.com/luzhijing" target="_blank" rel="noopener noreferrer">@luzhijing</a></li><li><a href="https://github.com/MarsXDM" target="_blank" rel="noopener noreferrer">@MarsXDM</a></li><li><a href="https://github.com/mh-boy" target="_blank" rel="noopener noreferrer">@mh-boy</a></li><li><a href="https://github.com/mk8310" target="_blank" rel="noopener noreferrer">@mk8310</a></li><li><a href="https://github.com/morningman" target="_blank" rel="noopener noreferrer">@morningman</a></li><li><a href="https://github.com/Myasuka" target="_blank" rel="noopener noreferrer">@Myasuka</a></li><li><a href="https://github.com/nimuyuhan" target="_blank" rel="noopener noreferrer">@nimuyuhan</a></li><li><a href="https://github.com/pan3793" target="_blank" rel="noopener noreferrer">@pan3793</a></li><li><a href="https://github.com/PatrickNicholas" target="_blank" rel="noopener noreferrer">@PatrickNicholas</a></li><li><a href="https://github.com/pengxiangyu" target="_blank" rel="noopener noreferrer">@pengxiangyu</a></li><li><a href="https://github.com/pierre94" target="_blank" rel="noopener noreferrer">@pierre94</a></li><li><a href="https://github.com/qidaye" target="_blank" rel="noopener noreferrer">@qidaye</a></li><li><a href="https://github.com/qzsee" target="_blank" rel="noopener noreferrer">@qzsee</a></li><li><a href="https://github.com/shiyi23" target="_blank" rel="noopener noreferrer">@shiyi23</a></li><li><a href="https://github.com/smallhibiscus" target="_blank" rel="noopener noreferrer">@smallhibiscus</a></li><li><a href="https://github.com/songenjie" target="_blank" rel="noopener noreferrer">@songenjie</a></li><li><a href="https://github.com/spaces-X" target="_blank" rel="noopener noreferrer">@spaces-X</a></li><li><a href="https://github.com/stalary" target="_blank" rel="noopener noreferrer">@stalary</a></li><li><a href="https://github.com/stdpain" target="_blank" rel="noopener noreferrer">@stdpain</a></li><li><a href="https://github.com/Stephen-Robin" target="_blank" rel="noopener noreferrer">@Stephen-Robin</a></li><li><a href="https://github.com/Sunt-ing" target="_blank" rel="noopener noreferrer">@Sunt-ing</a></li><li><a href="https://github.com/Taaang" target="_blank" rel="noopener noreferrer">@Taaang</a></li><li><a href="https://github.com/tarepanda1024" target="_blank" rel="noopener noreferrer">@tarepanda1024</a></li><li><a href="https://github.com/tianhui5" target="_blank" rel="noopener noreferrer">@tianhui5</a></li><li><a href="https://github.com/tinkerrrr" target="_blank" rel="noopener noreferrer">@tinkerrrr</a></li><li><a href="https://github.com/TobKed" target="_blank" rel="noopener noreferrer">@TobKed</a></li><li><a href="https://github.com/ucasfl" target="_blank" rel="noopener noreferrer">@ucasfl</a></li><li><a href="https://github.com/Userwhite" target="_blank" rel="noopener noreferrer">@Userwhite</a></li><li><a href="https://github.com/vinson0526" target="_blank" rel="noopener noreferrer">@vinson0526</a></li><li><a href="https://github.com/wangbo" target="_blank" rel="noopener noreferrer">@wangbo</a></li><li><a href="https://github.com/wangliansong" target="_blank" rel="noopener noreferrer">@wangliansong</a></li><li><a href="https://github.com/wangshuo128" target="_blank" rel="noopener noreferrer">@wangshuo128</a></li><li><a href="https://github.com/weajun" target="_blank" rel="noopener noreferrer">@weajun</a></li><li><a href="https://github.com/weihongkai2008" target="_blank" rel="noopener noreferrer">@weihongkai2008</a></li><li><a href="https://github.com/weizuo93" target="_blank" rel="noopener noreferrer">@weizuo93</a></li><li><a href="https://github.com/WindyGao" target="_blank" rel="noopener noreferrer">@WindyGao</a></li><li><a href="https://github.com/wunan1210" target="_blank" rel="noopener noreferrer">@wunan1210</a></li><li><a href="https://github.com/wuyunfeng" target="_blank" rel="noopener noreferrer">@wuyunfeng</a></li><li><a href="https://github.com/xhmz" target="_blank" rel="noopener noreferrer">@xhmz</a></li><li><a href="https://github.com/xiaokangguo" target="_blank" rel="noopener noreferrer">@xiaokangguo</a></li><li><a href="https://github.com/xiaoxiaopan118" target="_blank" rel="noopener noreferrer">@xiaoxiaopan118</a></li><li><a href="https://github.com/xinghuayu007" target="_blank" rel="noopener noreferrer">@xinghuayu007</a></li><li><a href="https://github.com/xinyiZzz" target="_blank" rel="noopener noreferrer">@xinyiZzz</a></li><li><a href="https://github.com/xuliuzhe" target="_blank" rel="noopener noreferrer">@xuliuzhe</a></li><li><a href="https://github.com/xxiao2018" target="_blank" rel="noopener noreferrer">@xxiao2018</a></li><li><a href="https://github.com/xy720" target="_blank" rel="noopener noreferrer">@xy720</a></li><li><a href="https://github.com/yangzhg" target="_blank" rel="noopener noreferrer">@yangzhg</a></li><li><a href="https://github.com/yx91490" target="_blank" rel="noopener noreferrer">@yx91490</a></li><li><a href="https://github.com/zbtzbtzbt" target="_blank" rel="noopener noreferrer">@zbtzbtzbt</a></li><li><a href="https://github.com/zenoyang" target="_blank" rel="noopener noreferrer">@zenoyang</a></li><li><a href="https://github.com/zh0122" target="_blank" rel="noopener noreferrer">@zh0122</a></li><li><a href="https://github.com/zhangboya1" target="_blank" rel="noopener noreferrer">@zhangboya1</a></li><li><a href="https://github.com/zhangstar333" target="_blank" rel="noopener noreferrer">@zhangstar333</a></li><li><a href="https://github.com/zuochunwei" target="_blank" rel="noopener noreferrer">@zuochunwei</a></li></ul>]]></content:encoded>
            <category>版本发布</category>
        </item>
    </channel>
</rss>